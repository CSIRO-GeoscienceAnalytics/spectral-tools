{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bunch of bits and pieces that will hopefully help you produce outputs for the GSNSW HyMap data.\n",
    "Personally I dont like notebooks and I am not sure if this will actually be a help or a hindrance to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, lets do some library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spectral.io.envi as envi\n",
    "from scipy.interpolate import interp1d\n",
    "from spectraltools.hulls.convexhulls import uc_hulls\n",
    "from spectraltools.extraction.extraction import extract_spectral_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the HyMap data. We will then look for all *ref.bil files in that directory and its subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(r\"Z:\\source\\GSNSW HyMap Data\\AIR_2002_gov_Broken_Hill_HySp_0352\\Processed_Raw_Data\")\n",
    "files = [val for val in path.glob(r'**/*ref.bil')]\n",
    "file_pairs = [(val, Path(str(val).replace('.bil', '.hdr'))) for val in files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some products we want. In this case I am only going to consider depth related products. The reason being that they are super simple to define and are fast to produce.\n",
    "I will do an example of a more comprehensive feature extracted product after. Be warned though that they are not fast due to the size of the spectral imagery. One HyMap image of 512 columns x 8500 rows x 126 bands is roughly the equivelant of 42km of drillcore. Wow!\n",
    "\n",
    "Additionally, I dont really know how you would make use of multiprocessing in a notebook. In the python file its easy (refer to that if needed)\n",
    "\n",
    "Just for your interest:\n",
    "The cell below took 64 minutes to run on my standard laptop. It produced the 5 products for 41 HyMap images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our depth products. We do this by using start and stop wavelength domains. If you use a list of these then you can generate multiple products in a single loop\n",
    "products = [(550, 750), (700, 1300), (2050, 2150), (2100, 2250), (2210, 2300)]\n",
    "bands = []\n",
    "for files in file_pairs:\n",
    "    # create an output directory\n",
    "    products_dir = files[0].parent / 'depth_products'\n",
    "    products_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # get the image data\n",
    "    img_data = envi.open(str(files[1]), str(files[0]))\n",
    "    bands = 1000.0*np.array(img_data.bands.centers)\n",
    "\n",
    "    for product in products:\n",
    "        # extract feature/s. Here you really want to set the ordinates_inspection_range to the thing you are after\n",
    "        features = extract_spectral_features(img_data[:,:,:], bands, do_hull=True, main_guard=False, ordinates_inspection_range=[product[0], product[1]], \n",
    "        distance=1, fit_type='crude')\n",
    "\n",
    "        # now write the product to file\n",
    "        md = {}\n",
    "        md['description'] = 'Simple maximum hull quotient depth between ' + str(product[0]) + ' and ' + str(product[1])\n",
    "        md['lines'] = img_data.metadata['lines']\n",
    "        md['samples'] = img_data.metadata['samples']\n",
    "        md['bands'] = '1' #might be 1, might be more. Depending on what you produced.\n",
    "        md['data type'] = '4' #float32 see https://www.l3harrisgeospatial.com/docs/idl_data_types.html\n",
    "        md['interleave'] = 'bip'\n",
    "        band_name = str(product[0]) + '_' + str(product[1])\n",
    "        md['band names'] = [band_name]\n",
    "        fileout_name = band_name+'.hdr'\n",
    "        fileout_name = str(products_dir / fileout_name)\n",
    "        img_out = envi.create_image(fileout_name, md, force=True)\n",
    "        img_out_memmap = img_out.open_memmap(writeable=True)\n",
    "        img_out_memmap = features.extracted_features[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything from this point forward is not setup to run through the entire list of HyMap files. However, the approach would be exactly the same as the cell above. You would create a loop that runs over the file_pairs and does various things like the processing you want and then writing outputs to files (dependent on what you want of course).\n",
    "\n",
    "I have left them as small snippets so as not to confuse the whole notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to do some hull quotient stuff ourself. This is how you can do it for a single file. Again loop and output as required like the above stuff. However, this is really what the extract_spectral_features with fit_type = 'crude' is doing. Just figured you might want a bit more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just do the first BH file\n",
    "single_image = envi.open(str(file_pairs[0][1]), str(file_pairs[0][0]))\n",
    "bands = 1000.0*np.array(single_image.bands.centers)\n",
    "# let define where we want to look\n",
    "indices = np.searchsorted(bands, [2100, 2250])\n",
    "# lets set the data into reflectance between 0-1. You need to directely reference the images like this as the spectral library uses numpy memmaps to reference the data when it is an image file\n",
    "temp_img = single_image[:,:,:]/10000.0\n",
    "# get the hull corrected image\n",
    "hull_corrected_image = uc_hulls(bands[indices[0]:indices[1]+1], temp_img[:,:,indices[0]:indices[1]+1], 0)\n",
    "# can now find out what the maximum depth etc is. From a memory perspective I would normally just tack the .max(axis=2) onto the previous line\n",
    "max_depth = hull_corrected_image.max(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to extract some features and do some clustering?\n",
    "A HUGE HUGE note here!!!\n",
    "The images in terms of spectral processing really are quite large and are equivelant to tens of km's of drillcore so they take a long time. This probably needs to be done on bowen and it should really be done in a main guard. In the e.g. bit below the process_my_hymap_stuff() would allow one to use the main_guard = True keyword in extract_spectral_features\n",
    "I am not sure how one implements that on bowen though (Fang should know how). Ultimately some of this stuff is better run not in a notebook but in a scirpt/s \n",
    "\n",
    "e.g\n",
    "\n",
    "def process_my_hymap_stuff():\n",
    "    # 1) find TSG files as above\n",
    "    # 2) enter loop for found files\n",
    "    # 3) extract features where you want the wavelengths, depths and FWHM\n",
    "    extract_spectral_features(image_data[:,:,:], bands, do_hull=True, max_features = 3, main_guard=True, ordinates_inspection_range=[2100, 2390],\n",
    "        distance=2, fit_type='cheb', resolution=1)\n",
    "\n",
    "if __name__ == '__main__\":\n",
    "    process_my_hymap_stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets open our image\n",
    "# lets just do the first BH file as previously. I am only reopening them for this cell as a demonstartion. No need to continusouly reopen these\n",
    "single_image = envi.open(str(file_pairs[0][1]), str(file_pairs[0][0]))\n",
    "bands = 1000.0*np.array(single_image.bands.centers)\n",
    "# now lets do a feature extraction. \n",
    "features = extract_spectral_features(single_image[:,:,:], bands, do_hull=True, max_features = 2, ordinates_inspection_range=[2100, 2390],\n",
    "        distance=2, fit_type='cheb', resolution=1, main_guard=False) #note that main_guard is False here. Super slow!!!\n",
    "# can cluster features if wanted. Need to be warned though this might not scale very well with really large datasets an aletrnative might be needed here\n",
    "clst = hdbscan.HDBSCAN(min_cluster_size=10, cluster_selection_epsilon=3)\n",
    "# lets cluster on the 2 deepest wavelengths. The reshape is to flatten the data into a Nxfeatures array since it was originally from the entire image\n",
    "clst.fit(features.extracted_features[:,:,0,[0, 1]].reshape(-1, 2))\n",
    "# show me the cluster labels\n",
    "labels = clst.labels_\n",
    "\n",
    "plt.scatter(features.extracted_features[:,:,0,0], features.extracted_features[:,:,0,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about if you want the GFZ spectral libraries. Well here is how you would grab one of them. Again just stick stuff in a loop if you want to collect them all up at onnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get a GFZ spectral library and put it in the same spectral space as the HyMap data. This assumes you have defined the HyMap bands already\n",
    "path = Path(r\"Z:\\source\\GFZ_Spectral_Libraries\\Koerting_GFZ_libs\\2019-004_Koerting-et-al_ReMin_REO_version-2.0\\hyperspectral-libraries\")\n",
    "files = [r\"GFZ_HySpex_REMin\", r\"GFZ_HySpex_REMin.hdr\"]\n",
    "gfz_data = envi.open(str(path / files[1]), str(path / files[0]))\n",
    "# lets setup an interpolating function so we can interpolate the spectra to the HyMap wavelengths\n",
    "f = interp1d(gfz_data.bands.centers, gfz_data.spectra/10000.0, fill_value='extrapolate', kind='cubic')\n",
    "# convert our spectral library to the HyMap wavelengths (actually just a 1D interpolation). Remember they are reflectance*10000\n",
    "new_gfz_lib = f(bands) # bands was defined somewhere earlier. If not its the HyMap bands. Both the GFZ and HyMap bands need to be in the same units"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d94db0c721b2dfb763b88a025a23890360800f099a2583c521e1fb9e956f7e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
