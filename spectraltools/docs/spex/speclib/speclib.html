<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>spex.speclib.speclib API documentation</title>
<meta name="description" content="THIS IS A MESS AT THIS STAGE AND SHOULD BE IGNORED. I NEED TO CLEAN IT UP â€¦" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>spex.speclib.speclib</code></h1>
</header>
<section id="section-intro">
<p>THIS IS A MESS AT THIS STAGE AND SHOULD BE IGNORED. I NEED TO CLEAN IT UP</p>
<p>SO the documentation is this: DON'T USE ME</p>
<p>The references internally refer to data sources that I am almost certain I have set up incorrectly in the package. By this
I mean its okat to call them how I do when its on my machine but when someone installs the package on their machine via
<code>python setup.py install</code> I think its meant to use resource packages.</p>
<p>So this I will fix a bit later</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># todo look for repeated code that can be busted out as methods
&#34;&#34;&#34;
THIS IS A MESS AT THIS STAGE AND SHOULD BE IGNORED. I NEED TO CLEAN IT UP

SO the documentation is this: DON&#39;T USE ME

The references internally refer to data sources that I am almost certain I have set up incorrectly in the package. By this
I mean its okat to call them how I do when its on my machine but when someone installs the package on their machine via
`python setup.py install` I think its meant to use resource packages.

So this I will fix a bit later
&#34;&#34;&#34;
import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from spex.ext.chulls import get_absorption
from sklearn.preprocessing import normalize
from sklearn.decomposition import non_negative_factorization
from spex.utilities.find_indices import find_indices
from scipy.interpolate import CubicSpline
import plotly.graph_objects as go
import seaborn as sb
from itertools import combinations
import pkg_resources


class SpectralMix(object):
    def __init__(self, instrument_wavelengths, spectral_input, spectral_range=None, hull=True, tir=False, library=0):
        &#34;&#34;&#34;
        Initialisation routine for the SpectralMix class object. This class attempts to perform spectral unmixing
        according to the users selected spectral library (3 available - 1 VNIR/SWIR, 2 TIR). An NMF model is used to
        perform linear spectral unmixing.

        Args:
            instrument_wavelengths (ndarry):
            spectral_input ()ndarray:
            spectral_range (list):
            hull (bool):
            tir (bool):
            library (int):
        &#34;&#34;&#34;
        libraries = [&#39;merged_vnswir_culled&#39;, &#39;tsg_tir_ms9&#39;, &#39;tsg_jhu_merge_tir&#39;]
        stream = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/colors_tsg.csv&#39;)
        self.colors = pd.read_csv(stream)

        self.spectral_input = spectral_input
        self.instrument_wavelengths = instrument_wavelengths

        self.library_df = None
        self.library_spectra = None
        self.library = library
        self.library_wavelengths = None

        self.instrument_library_spectra = None
        self.instrument_library_df = None

        self.average_instrument_library_spectra = None
        self.average_instrument_library_df = None

        # if any cuts are made to the spectral library e.g. drop spectra for whatever reason then the result is saved
        # to the culled_df and culled_spectra values so as not to destroy the original datasets
        self.culled_df = None
        self.culled_spectra = None
        self.which_culled = None
        self.cull_type = None

        self.hull = hull
        self.hull_type = 1
        self.spectral_range = spectral_range
        self.tir = tir
        if self.tir:
            self.hull = False

        self.nmf_results = None
        # this can take on one of three values: full, average or culled
        self.which_nmf = None
        self.rms_fit_error = None
        self.r2_fit_error = None

        #library = os.path.join(library_directory, libraries[library])
        # set some other variables up
        # ensure that the library doesnt require extrapolation
        library = libraries[library]
        self.set_library(library)
        self.convert_library_to_instrument()
        self.make_average_instrument_library()
        self.range_indices = find_indices(spectral_range, self.instrument_wavelengths)

    def set_external_library(self, wavelengths, spectra, names):
        &#34;&#34;&#34;
        Use external user supplied spectra as the spectral library
        Args:
            wavelengths (ndarry): An array of wavelengths (B) in nanometers corresponding to the number of entries in an
                individual spectrum contained in spectra.
            spectra (ndarray): An array of spectra (NxB) representing a user defined spectral endmember
            names (list): A list of names (N) for each spectrum in spectra

        Returns:
            Nothing: Sets internal variables

        &#34;&#34;&#34;
        self.library_df = pd.DataFrame(names, columns=[&#39;mineral&#39;])
        self.library_spectra = spectra
        self.library_wavelengths = wavelengths

        self.convert_library_to_instrument()
        self.make_average_instrument_library()
        self.range_indices = find_indices(self.spectral_range, self.instrument_wavelengths)

    def set_library(self, library=None):
        &#34;&#34;&#34;
        Set which spectral library to use (from the 3 inbuilt available)
        Args:
            library (str): The library to use ofr calculations

        Returns:
            Nothing: Sets internal variables
        &#34;&#34;&#34;
        if library is None:
            print(&#34;Nope. You didn&#39;t select a library&#34;)
        else:
            library_df = library + &#39;_df.csv&#39;
            library_spectra = library + &#39;_spectra.csv&#39;
            library_df_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_df)
            self.library_df = pd.read_csv(library_df_read, index_col=0)
            library_spectra_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_spectra)
            spectra_df = pd.read_csv(library_spectra_read, index_col=0)
            self.library_spectra = spectra_df.values
            self.library_wavelengths = 1000.0 * spectra_df.columns.values.astype(&#39;float&#39;)

    def get_library(self):
        &#34;&#34;&#34;
        Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra.
        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        return self.library_df, self.library_spectra

    def convert_library_to_instrument(self):
        &#34;&#34;&#34;
        Converts the internal spectral library to the same spectral domain as the spectral data that is to be analysed.

        Returns:
            Nothing: Sets internal variables

        &#34;&#34;&#34;
        cs = CubicSpline(self.library_wavelengths, self.library_spectra, extrapolate=False, axis=1)
        # want to exclude any wavelengths that required extrapolation
        in_range = np.unique(np.where(np.isfinite(cs(self.instrument_wavelengths)))[1])
        self.instrument_library_spectra = cs(self.instrument_wavelengths)[:, in_range]
        self.instrument_library_df = self.library_df.copy()
        # reassign the instrument data so the range matches the library
        self.instrument_wavelengths = self.instrument_wavelengths[in_range]
        self.spectral_input = self.spectral_input[:, in_range]

    def get_instrument_library(self):
        &#34;&#34;&#34;
        Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra at the same
            spectral space as the incoming spectral data.

        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        return self.instrument_library_df, self.instrument_library_spectra

    def make_average_instrument_library(self):
        &#34;&#34;&#34;
        This assumes that the spectral libraries contain mineral spectra. It groupsby the mineral names and produces an
            average spectrum for each mineral.

        Returns:
            Nothing: Sets the `internal average_instrument_library_spectra` and `average_instrument_library_df` variables

        &#34;&#34;&#34;
        grouped_dict = self.instrument_library_df.groupby(&#39;mineral&#39;).indices
        mean_spectra = []
        temp_df = pd.DataFrame()
        for val in grouped_dict:
            indices = grouped_dict[val]
            mean_spectra.append(np.mean(self.instrument_library_spectra[indices, :], axis=0))
            temp_df = temp_df.append(self.instrument_library_df.iloc[indices[0], :])
        temp_df = temp_df.reset_index(drop=True)

        self.average_instrument_library_spectra = np.asarray(mean_spectra)
        self.average_instrument_library_df = temp_df

    def get_average_instrument_library(self):
        &#34;&#34;&#34;
        Returns the instrument spectral library averages (grouped and averaged based on mineral name)

        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        if self.average_instrument_library_df is None:
            self.make_average_instrument_library()
        return self.average_instrument_library_df, self.average_instrument_library_spectra

    def tag_spectra_below_a_maximum_threshold(self, threshold=0.01, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            threshold ():
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        return np.max(inst_spec, axis=1) &lt; threshold

    def r2_error(self, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        synth = np.dot(self.nmf_results[0], self.nmf_results[1])

        # normalise the spectra
        synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

        # store the result and return them
        from scipy.stats import pearsonr
        r2 = [pearsonr(val1, val2)[0] for val1, val2 in zip(inst_spec, synthetics)]

        return np.asarray(r2)

    def rms_error(self, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        synth = np.dot(self.nmf_results[0], self.nmf_results[1])

        # normalise the spectra
        synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

        # store the result and return them
        rms_error = np.sqrt(
            np.sum(np.square(inst_spec - synthetics), axis=1) / wavelengths.shape[0])
        return rms_error

    def fit(self, fit_to=&#39;full&#39;, solver=&#39;mu&#39;, threshold=1.e-4):
        &#34;&#34;&#34;

        Args:
            fit_to ():
            solver ():
            threshold ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        # store what we performed the NMF on
        self.which_nmf = fit_to

        # normalise the spectra
        lib_spec, inst_spec = self._normalise_the_spectra(inst_spec, lib_spec)

        # do the NMF calculation
        if &#39;mu&#39; in solver:
            nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                                     n_components=lib_spec.shape[0], max_iter=600, solver=&#39;mu&#39;,
                                                    beta_loss=1, tol=1.e-5, random_state=42)
        else:
            nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                                 n_components=lib_spec.shape[0], max_iter=600, solver=&#39;cd&#39;,
                                                 beta_loss=2, random_state=42, tol=1.e-4)


        # apply a threshold to zero out ridiculously small values
        indices = np.where(nmf_results[0] &lt; threshold)
        nmf_results[0][indices] = 0.0

        # normalize the abundance values between 0 and 1
        part_one = nmf_results[0] / np.expand_dims(np.sum(nmf_results[0], axis=1), axis=1)

        # store the result and return them
        self.nmf_results = part_one, nmf_results[1]
        rms_error = self.rms_error(fit_to=fit_to)
        r2_error = self.r2_error(fit_to=fit_to)
        self.rms_fit_error = rms_error
        self.r2_fit_error = r2_error
        return part_one, nmf_results[1], rms_error, r2_error

    @staticmethod
    def _normalise_the_spectra(inst_spec, lib_spec):
        &#34;&#34;&#34;

        Args:
            inst_spec ():
            lib_spec ():

        Returns:

        &#34;&#34;&#34;
        lib_spec = normalize(lib_spec, norm=&#39;max&#39;, axis=1)
        inst_spec = normalize(inst_spec, norm=&#39;max&#39;, axis=1)
        return lib_spec, inst_spec

    def _hull_corrections(self, wavelengths, inst_spec, lib_spec, tir=False):
        &#34;&#34;&#34;

        Args:
            wavelengths ():
            inst_spec ():
            lib_spec ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        inst_hull = get_absorption(wavelengths, inst_spec, 2)
        if tir:
            lib_spec = get_absorption(wavelengths, 1.0 - lib_spec, self.hull_type)
            inst_spec = get_absorption(wavelengths, 1.0 - inst_spec, self.hull_type)
        else:
            lib_spec = get_absorption(wavelengths, lib_spec, self.hull_type)
            inst_spec = get_absorption(wavelengths, inst_spec, self.hull_type)

        lib_spec = np.nan_to_num(lib_spec)
        inst_spec = np.nan_to_num(inst_spec)
        lib_spec[lib_spec &lt; 0] = 0
        inst_spec[inst_spec &lt; 0] = 0

        return lib_spec, inst_spec, inst_hull

    def get_library_and_instrument_data(self, which_library):
        &#34;&#34;&#34;

        Args:
            which_library ():

        Returns:

        &#34;&#34;&#34;
        lib_df = None
        lib_spec = None
        range_index = self.range_indices

        inst_spec = self.spectral_input[:, range_index[0]:range_index[1]]
        if which_library == &#39;full&#39;:
            lib_df = self.instrument_library_df
            lib_spec = self.instrument_library_spectra[:, range_index[0]:range_index[1]]
        elif which_library == &#39;average&#39;:
            lib_df = self.average_instrument_library_df
            lib_spec = self.average_instrument_library_spectra[:, range_index[0]:range_index[1]]
        elif which_library == &#39;culled&#39;:
            lib_df = self.culled_df
            lib_spec = self.culled_spectra

        wavelengths = self.instrument_wavelengths[range_index[0]:range_index[1]]
        lib_spec[lib_spec &lt; 0] = 0
        inst_spec[inst_spec &lt; 0] = 0
        return lib_df, lib_spec, inst_spec, wavelengths

    def get_nmf_results(self):
        &#34;&#34;&#34;

        Returns:

        &#34;&#34;&#34;
        return self.nmf_results, self.which_nmf

    def plot_spectral_fit_at_ordinate(self, value, ordinates, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                          fill_between=True, mask=0, title=None, color=None, additional_label=&#39;&#39;, legend=True, return_contributions=False):
        &#34;&#34;&#34;

        Args:
            value ():
            ordinates ():
            plot_type ():
            what ():
            top ():
            total_contribution ():
            ax ():
            fill_between ():
            mask ():
            title ():
            color ():
            additional_label ():
            legend ():
            return_contributions ():

        Returns:

        &#34;&#34;&#34;
        ax = ax or plt.gca()
        # get the fit
        nmf = self.nmf_results
        df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

        if not np.isscalar(mask):
            index = np.square(ordinates - ordinates[mask][np.square(ordinates[mask] - value).argmin()]).argmin()
            rms = self.rms_fit_error[mask][index]
            r2 = self.r2_fit_error[mask][index]
        else:
            index = np.square(ordinates - value).argmin()
            rms = self.rms_fit_error[index]
            r2 = self.r2_fit_error[index]

        args = np.argsort(nmf[0][index, :])[-top:]
        top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
        contributions = np.round(np.flip(nmf[0][index, args]), 2)

        # get total contribution
        if total_contribution:
            grp = df.groupby(what).indices
            name = []
            amount = []
            for val in grp:
                name.append(val)
                amount.append(np.sum(nmf[0][index, grp[val]]))

            args = np.argsort(amount)[-top:]
            contributions = np.round(np.asarray(amount)[args], 2)
            top_minerals = np.asarray(name)[args]
        return_minerals = (top_minerals, contributions)

        # get the nmf interpretation of the spectrum and the actual spectrum
        synthetic_spectrum = nmf[0][index, :].dot(nmf[1])
        actual_spectrum = instrument_spectra[index, :]

        # 1: TIR = True : Only need a baseline correction to the actual spectra
        # 2: Hull = True : Only need to get the actual spectra hull removed
        hull = None
        sf = None
        temp_spectrum = None
        if self.tir:
            actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
            sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        if self.hull:
            hull = get_absorption(wavelengths, actual_spectrum, 2)
            temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
            sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

        if sf is None:
            scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        else:
            scale_factor = sf

        # now its only about the display
        # can either be reflectance or hull
        # tir can only be reflectance
        if self.tir:
            synthetic_spectrum = synthetic_spectrum * scale_factor
        else:
            if plot_type == &#39;ref&#39;:
                synthetic_spectrum = hull - synthetic_spectrum * scale_factor
            else:
                synthetic_spectrum = synthetic_spectrum * scale_factor
                actual_spectrum = temp_spectrum

        if top != 0:
            minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
            seperator = &#39;, &#39;
            label = seperator.join(minerals) + &#39;, RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label
        else:
            label = &#39;RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label

        # actual_spectrum += offset
        # synthetic_spectrum += offset
        if fill_between:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            if color:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
            else:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
            line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.3)
            line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.3)
        else:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            if color:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
            else:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        ax.set_xlabel(&#39;Wavelength (nm)&#39;, fontsize=16)
        ax.set_ylabel(&#39;Reflectance&#39;, fontsize=16)
        if title:
            ax.set_title(title, fontsize=20)
        if legend:
            ax.legend()
        return wavelengths, actual_spectrum, synthetic_spectrum, return_minerals

    def plot_spectral_fit(self, index, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                          fill_between=True):
        &#34;&#34;&#34;

        Args:
            index ():
            plot_type ():
            what ():
            top ():
            total_contribution ():
            ax ():
            fill_between ():

        Returns:

        &#34;&#34;&#34;
        ax = ax or plt.gca()
        # get the fit
        nmf = self.nmf_results
        df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

        args = np.argsort(nmf[0][index, :])[-top:]
        top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
        contributions = np.round(np.flip(nmf[0][index, args]), 2)

        # get total contribution
        if total_contribution:
            grp = df.groupby(what).indices
            name = []
            amount = []
            for val in grp:
                name.append(val)
                amount.append(np.sum(nmf[0][index, grp[val]]))

            args = np.argsort(amount)[-top:]
            contributions = np.round(np.asarray(amount)[args], 2)
            top_minerals = np.asarray(name)[args]

        # get the nmf interpretation of the spectrum and the actual spectrum
        synthetic_spectrum = np.dot(nmf[0][index, :], nmf[1])
        actual_spectrum = instrument_spectra[index, :]

        # 1: TIR = True : Only need a baseline correction to the actual spectra
        # 2: Hull = True : Only need to get the actual spectra hull removed
        hull = None
        sf = None
        temp_spectrum = None
        if self.tir:
            actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
            sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        if self.hull:
            hull = get_absorption(wavelengths, actual_spectrum, 2)
            temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
            sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

        if sf is None:
            scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        else:
            scale_factor = sf

        # now its only about the display
        # can either be reflectance or hull
        # tir can only be reflectance
        if self.tir:
            synthetic_spectrum = synthetic_spectrum * scale_factor
        else:
            if plot_type == &#39;ref&#39;:
                synthetic_spectrum = hull - synthetic_spectrum * scale_factor
            else:
                synthetic_spectrum = synthetic_spectrum * scale_factor
                actual_spectrum = temp_spectrum

        minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
        seperator = &#39; + &#39;
        label = seperator.join(minerals)

        if fill_between:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
            line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.5)
            line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.5)
        else:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        ax.set_xlabel(&#39;Wavelength (nm)&#39;)
        ax.set_ylabel(&#39;Reflectance&#39;)
        ax.legend()
        return wavelengths, actual_spectrum, synthetic_spectrum

    def cull_by_rank(self, rank=10, direction=&#39;gt&#39;):
        &#34;&#34;&#34;

        Args:
            rank ():
            direction ():

        Returns:

        &#34;&#34;&#34;
        # cut out the last rank nmf results above or below e.g. cut the top 10 out top_or_bottom_cut(rank=10, direction=&#39;above)
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(np.sum(self.nmf_results[0], axis=0))
        orders = np.argsort(proportions)
        which_nmf = self.which_nmf

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)
        temp_df = temp_df.iloc[orders, :]
        temp_spectra = temp_spectra[orders, :]
        self.which_culled = which_nmf

        if direction.lower() == &#39;gt&#39;:
            temp_df = temp_df.iloc[-rank:, :].reset_index(drop=True)
            temp_spectra = temp_spectra[-rank:, :]
        else:
            temp_df = temp_df.iloc[:rank, :].reset_index(drop=True)
            temp_spectra = temp_spectra[:rank, :]

        self.cull_type = &#39;top_or_bottom_&#39; + direction
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        return self.fit(fit_to=&#39;culled&#39;)

    def keep_library_above(self, threshold=0.0):
        &#34;&#34;&#34;

        Args:
            threshold ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            self.which_nmf = &#39;full&#39;
            # print(&#39;You need to fit some data first&#39;)
            # return ()

        # see what the last nmf results were generated from
        which_nmf = self.which_nmf
        temp_df, temp_spectra, _, wavelengths = self.get_library_and_instrument_data(which_nmf)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, _, _ = self._hull_corrections(wavelengths, temp_spectra, temp_spectra, self.tir)

        indices = np.where(np.max(lib_spec, axis=1) &gt; threshold)[0]

        return self.keep_specific(keep_these=indices, indices_supplied=True)

    def keep_specific(self, keep_these=None, indices_supplied=False, keep_type=&#39;mineral&#39;):
        &#34;&#34;&#34;

        Args:
            keep_these ():
            indices_supplied ():
            keep_type ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            self.which_nmf = &#39;full&#39;
            # print(&#39;You need to fit some data first&#39;)
            # return ()

        # see what the last nmf results were generated from
        which_nmf = self.which_nmf
        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

        self.which_culled = which_nmf
        self.cull_type = &#39;grouped_&#39; + keep_type
        # first find out where the stuff is in the df so we can flag which spectra to drop as well
        if not indices_supplied:
            indices = temp_df[temp_df[keep_type].str.contains(&#39;|&#39;.join(keep_these))].index.values
        else:
            indices = keep_these

        if len(indices) &gt; 0:
            temp_df = temp_df.iloc[indices, :].reset_index(drop=True)
            temp_spectra = temp_spectra[indices, :]
            self.culled_df = temp_df
            self.culled_spectra = temp_spectra
            return self.fit(fit_to=&#39;culled&#39;)

    def drop_specific(self, drop_these=None, indices_supplied=False, drop_type=&#39;mineral&#39;, solver=&#39;mu&#39;):
        &#34;&#34;&#34;

        Args:
            drop_these ():
            indices_supplied ():
            drop_type ():
            solver ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            which_nmf = &#39;full&#39;
        else:
            # see what the last nmf results were generated from
            which_nmf = self.which_nmf

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

        self.which_culled = which_nmf
        self.cull_type = &#39;grouped_&#39; + drop_type
        # first find out where the stuff is in the df so we can flag which spectra to drop as well
        if not indices_supplied:
            indices = temp_df[temp_df[drop_type].str.contains(&#39;|&#39;.join(drop_these))].index.values
        else:
            indices = drop_these

        if len(indices) &gt; 0:
            temp_df = temp_df.drop(indices, axis=0).reset_index(drop=True)
            temp_spectra = np.delete(temp_spectra, indices, axis=0)
            self.culled_df = temp_df
            self.culled_spectra = temp_spectra
            return self.fit(fit_to=&#39;culled&#39;, solver=solver)

    def cull_by_individual_and_total_sample_contribution(self, cull_value1=None, cull_value2=None):
        &#34;&#34;&#34;

        Args:
            cull_value1 ():
            cull_value2 ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_nmf = self.nmf_results[0]
        if cull_value1:
            cull_value1 = cull_value1 / 100.0
        else:
            cull_value1 = 1.0 / temp_nmf.shape[1]

        if cull_value2:
            cull_value2 = cull_value2 / 100.0
        else:
            cull_value2 = 1.0 / temp_nmf.shape[1]

        args = np.where(temp_nmf &lt; cull_value1)
        temp_nmf[args[0], args[1]] = 0
        # now we add them up as a function of the number of samples
        sample_sum = np.sum(temp_nmf, axis=0) / temp_nmf.shape[0]
        args = np.where(sample_sum &gt; cull_value2)[0]

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)
        temp_spectra = temp_spectra[args, :]

        # store the culled data frame and spectral data and rerun the unmixing
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        self.which_culled = self.which_nmf

        self.cull_type = &#39;double_cull_&#39;  # + str(cull_value)
        return self.fit(fit_to=&#39;culled&#39;)

    def cull_by_cumulative_proportion(self, cull_value=10, direction=&#39;gt&#39;, cumulative=True):
        &#34;&#34;&#34;

        Args:
            cull_value ():
            direction ():
            cumulative ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, temp_spectra, temp_nmf = self.cull_entries(cumulative, direction, cull_value)

        # store the culled data frame and spectral data and rerun the unmixing
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        self.which_culled = self.which_nmf

        self.cull_type = &#39;proportion_&#39; + direction + str(cull_value)
        return self.fit(fit_to=&#39;culled&#39;)

    def cull_entries(self, cumulative, direction, proportion):
        &#34;&#34;&#34;

        Args:
            cumulative ():
            direction ():
            proportion ():

        Returns:

        &#34;&#34;&#34;
        # these are the individual spectral sample proportions in the library
        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        # set them from low to high
        orders = np.argsort(proportions)
        props = proportions[orders]

        temp_nmf = self.nmf_results
        t1 = temp_nmf[0][:, orders]
        t2 = temp_nmf[1][orders, :]
        temp_nmf = [t1, t2]

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
        temp_df = temp_df.iloc[orders, :].reset_index(drop=True)
        temp_spectra = temp_spectra[orders, :]

        cutoff_index = self._proportion_cutoff_indices(direction, proportion, props, cumulative=cumulative)
        temp_df = temp_df.iloc[cutoff_index, :].reset_index(drop=True)
        temp_spectra = temp_spectra[cutoff_index, :]
        t1 = temp_nmf[0][:, cutoff_index]
        t2 = temp_nmf[1][cutoff_index, :]
        temp_nmf = [t1, t2]
        return temp_df, temp_spectra, temp_nmf

    @staticmethod
    def _proportion_cutoff_indices(direction, proportion, props, cumulative=True):
        &#34;&#34;&#34;

        Args:
            direction ():
            proportion ():
            props ():
            cumulative ():

        Returns:

        &#34;&#34;&#34;
        if cumulative:
            if direction.lower() == &#39;gt&#39;:
                cutoff_index = np.where(np.cumsum(props) &gt;= proportion)[0]
            else:
                cutoff_index = np.where(np.cumsum(props) &lt;= proportion)[0]
            if len(cutoff_index) == 0:
                cutoff_index = range(props.shape[0])
        else:
            if direction.lower() == &#39;gt&#39;:
                cutoff_index = np.where(props &gt;= proportion)[0]
            else:
                cutoff_index = np.where(props &lt;= proportion)[0]
            if len(cutoff_index) == 0:
                cutoff_index = range(props.shape[0])

        return cutoff_index

    def plot_proportions(self, plot_what=&#39;mineral&#39;, stacked=True):
        &#34;&#34;&#34;

        Args:
            plot_what ():
            stacked ():

        Returns:

        &#34;&#34;&#34;
        # plot the proportions of the last NMF run
        # todo return the axes and the figure so people can put it where they want
        # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
        # your call

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        orders = np.argsort(proportions)
        props = proportions[orders]
        names = None

        which_nmf = self.which_nmf
        if which_nmf.lower() == &#39;full&#39;:
            names = self.instrument_library_df[plot_what].iloc[orders]
        elif which_nmf.lower() == &#39;average&#39;:
            names = self.average_instrument_library_df[plot_what].iloc[orders]
        elif which_nmf == &#39;culled&#39;:
            names = self.culled_df[plot_what].iloc[orders]

        # make a temporary data frame
        temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
        # todo allow people to change the color map
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if stacked:
            temp_df.plot.bar(stacked=True, legend=False, color=colors)
            # todo work out how many cols are needed based on len(names) and adjust accordingly
            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
            plt.subplots_adjust(right=0.55)
        else:
            plt.bar(np.arange(props.shape[0]), props, tick_label=names, color=colors)
            plt.xticks(rotation=90)
            plt.tight_layout()
        plt.show()

    def cull_by_grouped(self, cull_value=0.0, grouping=&#39;mineral&#39;):
        &#34;&#34;&#34;

        Args:
            cull_value ():
            grouping ():

        Returns:

        &#34;&#34;&#34;
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        _, names, props = self._group_and_sort_by_proportion(grouping)

        # see what values are below this &amp; drop them
        cull_this = np.where(props &lt;= cull_value)[0]
        if len(cull_this) &gt; 0:
            names = names[cull_this]
            return self.drop_specific(drop_these=names, drop_type=grouping)
        else:
            return 0

    def plot_grouped_proportions(self, group=None, stacked=True, ax=None):
        &#34;&#34;&#34;

        Args:
            group ():
            stacked ():
            ax ():

        Returns:

        &#34;&#34;&#34;
        if group is None:
            group = [&#39;mineral&#39;]
        ax = ax or plt.gca()
        # plot the proportions of the last NMF run
        # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
        # your call

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        cum_sum, names, props = self._group_and_sort_by_proportion(group)

        temp = []
        for index, name in enumerate(names):
            temp.append(name + &#39;|&#39; + str(np.round(props[index], 2)) + &#39;|&#39; + str(np.round(cum_sum[index], 2)))

        names = list(np.asarray(temp))

        # make a temporary data frame
        temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
        # todo allow people to change the color map
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))

        if len(group) &gt; 1:
            stacked = True
        if stacked:
            temp_df.plot.bar(stacked=True, legend=False, color=colors)
            # todo work out how many cols are needed based on len(names) and adjust accordingly
            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
            plt.subplots_adjust(right=0.4)
        else:
            plt.bar(names, props, color=colors)
            plt.xticks(rotation=90)
            plt.tight_layout()

        plt.show()

    def _group_and_sort_by_proportion(self, group):
        &#34;&#34;&#34;

        Args:
            group ():

        Returns:

        &#34;&#34;&#34;
        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        minerals_grouped = temp_df.groupby(group).indices
        names = []
        proportion = []
        for val in minerals_grouped:
            names.append(val)
            proportion.append(np.sum(proportions[minerals_grouped[val]]))
        orders = np.argsort(proportion)
        props = np.asarray(proportion)[orders]
        names = np.asarray(names)[orders]
        cumsum = np.cumsum(props)
        return cumsum, names, props

    def plot_stacked_weight(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=1, ax=None, legend_ax=None,
                            do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                            mask=0, title=&#34;Relative Mineral Proportions&#34;, xtitle=&#39;Depth (m)&#39;):
        &#34;&#34;&#34;

        Args:
            x_ordinate ():
            what_thing ():
            partitions ():
            ax ():
            legend_ax ():
            do_plotly ():
            save_name ():
            hide_value ():
            use_tsg_colors ():
            mask ():
            title ():
            xtitle ():

        Returns:

        &#34;&#34;&#34;
        if do_plotly is False:
            ax = ax or plt.gca()
            legend_ax = legend_ax or plt.gca()

        # plot the stacked weights from the last NMF run
        # which_nmf determines where the last result came from
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
        temp_weights = self.nmf_results[0].copy()
        temp_weights = temp_weights[:, args]
        names = np.unique(temp_df[what_thing].iloc[args])
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)

        # todo add in the nmf_results[1] into the mix so it can be passed back
        new_weight = []
        # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
        # mineral name todo change this a pandas groupby and indices call instead
        for name in names:
            args = np.where(temp_df[what_thing] == name)[0]
            new_weight.append(np.sum(temp_weights[:, args], axis=1))
        new_weight = np.transpose(np.asarray(new_weight))
        new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

        # find where the indices are that will let us split the data according to the user partition size
        split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
        if np.isscalar(mask):
            mask = np.ones(x_ordinate.shape).astype(bool)

        x_ordinate_split = np.split(x_ordinate, split_locations)
        new_weight_split = np.split(new_weight, split_locations)
        mask_split = np.split(mask, split_locations)

        depth = []
        width = []
        weight = []

        count = 0
        if np.min(np.diff(x_ordinate)) &lt; partitions:
            for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
                if xval.shape[0] &gt; 0:
                    depth.append(xval[0])
                    width.append(xval[-1]-xval[0])
                    any_masked = float(np.where(mask_val)[0].shape[0])
                    # if nothing is masked then dont average
                    if any_masked &gt; 0:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                    else:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0))
        else:
            depth = x_ordinate
            width = np.zeros((depth.shape[0])) + partitions
            weight = new_weight[mask]

        weight = np.asarray(weight)
        depth = np.asarray(depth)
        width = np.asarray(width)

        tdepth = [str(int(val)) for val in depth]
        new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if not do_plotly:
            new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
        else:
            if hide_value &gt; 0:
                args = np.where(weight &lt; hide_value)
                weight[args[0], args[1]] = np.nan
                # normalize
                weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

            data = []
            for var in np.arange(weight.shape[1]):
                if what_thing == &#39;mineral&#39;:
                    thing = &#39;Mineral&#39;
                elif what_thing == &#39;group&#39;:
                    thing = &#39;Group&#39;
                else:
                    use_tsg_colors = False

            color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours.csv&#34;)
            for val in np.unique(temp_df[&#39;group&#39;]):
                unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
                number_of_minerals = unique_minerals.shape[0]
                group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
                # lets get alpha values
                rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
                alphas = np.linspace(1.0, 0.5, number_of_minerals)
                # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
                # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
                # rgb = rgb.astype(int)
                for index, mineral in enumerate(unique_minerals):
                    #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                    color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                    location = np.where(names == mineral)[0][0]
                    data.append(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                         marker_color=color))

            fig = go.Figure(data=data)
            # Change the bar mode
            # todo put in keywords for titles and labels
            title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
            fig.update_layout(barmode=&#39;stack&#39;, title=title, xaxis_title=xtitle,
                              yaxis_title=&#34;Relative Proportion&#34;, legend_orientation=&#34;h&#34;, font_size=20)
            fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
            fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
            fig.write_html(save_name+&#34;.html&#34;)

        return names, depth, np.nan_to_num(weight, 0)

    def plot_stacked_weight_hack(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=100, ax=None, legend_ax=None,
                            do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                            mask=0, title=&#34;Relative Mineral Proportions&#34;):
        &#34;&#34;&#34;

        Args:
            x_ordinate ():
            what_thing ():
            partitions ():
            ax ():
            legend_ax ():
            do_plotly ():
            save_name ():
            hide_value ():
            use_tsg_colors ():
            mask ():
            title ():

        Returns:

        &#34;&#34;&#34;

        if do_plotly is False:
            ax = ax or plt.gca()
            legend_ax = legend_ax or plt.gca()

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
        temp_weights = self.nmf_results[0].copy()[:, args]
        names = np.unique(temp_df[what_thing].iloc[args])
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)

        new_weight = []
        # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
        # mineral name todo change this a pandas groupby and indices call instead
        for name in names:
            args = np.where(temp_df[what_thing] == name)[0]
            new_weight.append(np.sum(temp_weights[:, args], axis=1))
        new_weight = np.transpose(np.asarray(new_weight))
        new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

        # find where the indices are that will let us split the data according to the user partition size
        split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
        if np.isscalar(mask):
            mask = np.ones(x_ordinate.shape).astype(bool)

        x_ordinate_split = np.split(x_ordinate, split_locations)
        new_weight_split = np.split(new_weight, split_locations)
        mask_split = np.split(mask, split_locations)

        depth = []
        width = []
        weight = []

        count=0
        if np.min(np.diff(x_ordinate)) &lt; partitions:
            for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
                if xval.shape[0] &gt; 0:
                    depth.append(xval[0])
                    width.append(xval[-1]-xval[0])
                    any_masked = float(np.where(mask_val)[0].shape[0])
                    # if nothing is masked then dont average
                    if any_masked &gt; 0:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                    else:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0))
        else:
            depth = x_ordinate
            width = np.zeros((depth.shape[0])) + partitions
            weight = new_weight[mask]

        weight = np.asarray(weight)
        depth = np.asarray(depth)
        width = np.asarray(width)

        tdepth = [str(int(val)) for val in depth]
        new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if not do_plotly:
            new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
        else:
            if hide_value &gt; 0:
                args = np.where(weight &lt; hide_value)
                weight[args[0], args[1]] = np.nan
                # normalize
                weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

            from plotly.subplots import make_subplots
            fig = make_subplots(rows=3, cols=1, #shared_xaxes=True,
                                specs=[[{}], [{&#34;rowspan&#34;:2}], [None]])

            # todo add in a bit for group plots not just mineral
            data = []
            color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours_mkII.csv&#34;)
            for val in np.unique(temp_df[&#39;group&#39;]):
                unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
                number_of_minerals = unique_minerals.shape[0]
                group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
                # lets get alpha values
                rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
                alphas = np.linspace(1.0, 0.5, number_of_minerals)
                # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
                # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
                # rgb = rgb.astype(int)
                for index, mineral in enumerate(unique_minerals):
                    #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                    color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                    location = np.where(names == mineral)[0][0]
                    fig.add_trace(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                         marker_color=color), row=2, col=1)

            # MSDP11 HACK
            msdp11_df = pd.read_csv(&#39;msdp11_log.csv&#39;)
            lithology = msdp11_df.columns.values[2:]
            x = msdp11_df[&#39;X&#39;].values.astype(int)
            w = msdp11_df[&#39;Width&#39;].values.astype(int)
            colors=[&#34;brown&#34;, &#34;saddlebrown&#34;, &#34;lightyellow&#34;, &#34;pink&#34;, &#34;red&#34;, &#34;skyblue&#34;, &#34;olivedrab&#34;, &#34;darkgray&#34;, &#34;gray&#34;, &#34;indianred&#34;, &#34;purple&#34;]

            for index, var in enumerate(lithology):
                y = msdp11_df[var].values
                fig.add_trace(go.Bar(name=var, x=x+w/2, y=y, width=w, marker_color=colors[index]), row=1, col=1)

            # Change the bar mode
            # todo put in keywords for titles and labels
            title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
            fig.update_layout(barmode=&#39;stack&#39;, title=title, legend_orientation=&#34;h&#34;, font_size=20)
            fig.update_yaxes(showticklabels=False, row=1, col=1)
            fig.update_xaxes(title_text=&#39;Depth (m)&#39;, row=2, col=1)
            fig.update_yaxes(title_text=&#39;Relative Proportion&#39;, row=2, col=1)
            fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
            fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
            fig.write_html(save_name+&#34;.html&#34;)

        return names, depth, np.nan_to_num(weight, 0)

    def plot_library_spectra(self, search_item=&#39;mineral&#39;, names=None, plot_hull=False, tir=False):
        &#34;&#34;&#34;

        Args:
            search_item ():
            names ():
            plot_hull ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        if names is None:
            return 0
        df = self.instrument_library_df
        wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
        spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]
        if plot_hull:
            if tir:
                spectra = get_absorption(wavelengths, 1.0 - spectra, 1)
            else:
                spectra = get_absorption(wavelengths, spectra, 1)

        indices = df.loc[df[search_item].isin(names)].index.values
        if len(indices) &gt; 0:
            for val in indices:
                plt.plot(wavelengths, spectra[val, :], label=df[search_item].iloc[val])
            plt.legend()
            plt.show()

    def compare_instrument_spectra_to_specific(self, index, search_type=&#39;mineral&#39;, search_item=&#39;kaolinite&#39;, hull=False,
                                               normalise=False):
        &#34;&#34;&#34;

        Args:
            index ():
            search_type ():
            search_item ():
            hull ():
            normalise ():

        Returns:

        &#34;&#34;&#34;
        df = self.instrument_library_df
        wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
        spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]

        instrument_data = self.spectral_input[index, self.range_indices[0]:self.range_indices[1]]
        if hull:
            instrument_data = get_absorption(wavelengths, instrument_data, 1)
        if normalise:
            instrument_data = instrument_data / np.max(instrument_data)

        indices = np.where(df[search_type].str.contains(search_item))[0]
        if len(indices) &gt; 0:
            plt.plot(wavelengths, instrument_data, label=&#39;Instrument&#39;, color=&#39;k&#39;)
            for val in indices:
                spectrum = spectra[val, :]
                if hull:
                    spectrum = get_absorption(wavelengths, spectrum, 1)
                if normalise:
                    spectrum = spectrum / np.max(spectrum)
                plt.plot(wavelengths, spectrum, label=df[search_type].iloc[val])
            plt.legend()
            plt.show()

    def mixtures(self, which_library=&#39;full&#39;, tir=False):
        &#34;&#34;&#34;
        
        Args:
            which_library ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        # singleton
        lib_df, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(which_library)
        lib_spec, inst_spec, inst_hull = self._hull_corrections(wavelengths, inst_spec, lib_spec, tir=tir)

        # get all of the possible combinations of the end members up to a max mixture level e.g 1 through to 4
        lib_elements = list(np.arange(lib_spec.shape[0]))
        mixtures = []
        max_mixture_level = 4 # hard coded for trial
        for val in range(1, max_mixture_level+1):
            mixtures.append(list(combinations(lib_elements, val)))

        # run the NMF to calculate the weights for the potential mixture levels
        rms_error = []
        for val in mixtures[0]:
            nmf_results = non_negative_factorization(inst_spec, H=np.reshape(lib_spec[val[1], :], [1, -1]),
                                                     update_H=False, init=None,
                                                     n_components=2, max_iter=600, solver=&#39;mu&#39;,
                                                     beta_loss=1, tol=1.e-4, random_state=42)[:2]
            rms_error.append(np.sqrt(np.sum(np.square(np.dot(nmf_results[0][0], nmf_results[0][1]) - inst_spec), axis=1)))

        # calculate the rms error between the various mixture level fits
        # pick the lowest rms error as the winner for a given spectrum (not sure if this will just default to the one with the most mixtures)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="spex.speclib.speclib.SpectralMix"><code class="flex name class">
<span>class <span class="ident">SpectralMix</span></span>
<span>(</span><span>instrument_wavelengths, spectral_input, spectral_range=None, hull=True, tir=False, library=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialisation routine for the SpectralMix class object. This class attempts to perform spectral unmixing
according to the users selected spectral library (3 available - 1 VNIR/SWIR, 2 TIR). An NMF model is used to
perform linear spectral unmixing.</p>
<h2 id="args">Args</h2>
<p>instrument_wavelengths (ndarry):
spectral_input ()ndarray:
spectral_range (list):
hull (bool):
tir (bool):
library (int):</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SpectralMix(object):
    def __init__(self, instrument_wavelengths, spectral_input, spectral_range=None, hull=True, tir=False, library=0):
        &#34;&#34;&#34;
        Initialisation routine for the SpectralMix class object. This class attempts to perform spectral unmixing
        according to the users selected spectral library (3 available - 1 VNIR/SWIR, 2 TIR). An NMF model is used to
        perform linear spectral unmixing.

        Args:
            instrument_wavelengths (ndarry):
            spectral_input ()ndarray:
            spectral_range (list):
            hull (bool):
            tir (bool):
            library (int):
        &#34;&#34;&#34;
        libraries = [&#39;merged_vnswir_culled&#39;, &#39;tsg_tir_ms9&#39;, &#39;tsg_jhu_merge_tir&#39;]
        stream = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/colors_tsg.csv&#39;)
        self.colors = pd.read_csv(stream)

        self.spectral_input = spectral_input
        self.instrument_wavelengths = instrument_wavelengths

        self.library_df = None
        self.library_spectra = None
        self.library = library
        self.library_wavelengths = None

        self.instrument_library_spectra = None
        self.instrument_library_df = None

        self.average_instrument_library_spectra = None
        self.average_instrument_library_df = None

        # if any cuts are made to the spectral library e.g. drop spectra for whatever reason then the result is saved
        # to the culled_df and culled_spectra values so as not to destroy the original datasets
        self.culled_df = None
        self.culled_spectra = None
        self.which_culled = None
        self.cull_type = None

        self.hull = hull
        self.hull_type = 1
        self.spectral_range = spectral_range
        self.tir = tir
        if self.tir:
            self.hull = False

        self.nmf_results = None
        # this can take on one of three values: full, average or culled
        self.which_nmf = None
        self.rms_fit_error = None
        self.r2_fit_error = None

        #library = os.path.join(library_directory, libraries[library])
        # set some other variables up
        # ensure that the library doesnt require extrapolation
        library = libraries[library]
        self.set_library(library)
        self.convert_library_to_instrument()
        self.make_average_instrument_library()
        self.range_indices = find_indices(spectral_range, self.instrument_wavelengths)

    def set_external_library(self, wavelengths, spectra, names):
        &#34;&#34;&#34;
        Use external user supplied spectra as the spectral library
        Args:
            wavelengths (ndarry): An array of wavelengths (B) in nanometers corresponding to the number of entries in an
                individual spectrum contained in spectra.
            spectra (ndarray): An array of spectra (NxB) representing a user defined spectral endmember
            names (list): A list of names (N) for each spectrum in spectra

        Returns:
            Nothing: Sets internal variables

        &#34;&#34;&#34;
        self.library_df = pd.DataFrame(names, columns=[&#39;mineral&#39;])
        self.library_spectra = spectra
        self.library_wavelengths = wavelengths

        self.convert_library_to_instrument()
        self.make_average_instrument_library()
        self.range_indices = find_indices(self.spectral_range, self.instrument_wavelengths)

    def set_library(self, library=None):
        &#34;&#34;&#34;
        Set which spectral library to use (from the 3 inbuilt available)
        Args:
            library (str): The library to use ofr calculations

        Returns:
            Nothing: Sets internal variables
        &#34;&#34;&#34;
        if library is None:
            print(&#34;Nope. You didn&#39;t select a library&#34;)
        else:
            library_df = library + &#39;_df.csv&#39;
            library_spectra = library + &#39;_spectra.csv&#39;
            library_df_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_df)
            self.library_df = pd.read_csv(library_df_read, index_col=0)
            library_spectra_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_spectra)
            spectra_df = pd.read_csv(library_spectra_read, index_col=0)
            self.library_spectra = spectra_df.values
            self.library_wavelengths = 1000.0 * spectra_df.columns.values.astype(&#39;float&#39;)

    def get_library(self):
        &#34;&#34;&#34;
        Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra.
        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        return self.library_df, self.library_spectra

    def convert_library_to_instrument(self):
        &#34;&#34;&#34;
        Converts the internal spectral library to the same spectral domain as the spectral data that is to be analysed.

        Returns:
            Nothing: Sets internal variables

        &#34;&#34;&#34;
        cs = CubicSpline(self.library_wavelengths, self.library_spectra, extrapolate=False, axis=1)
        # want to exclude any wavelengths that required extrapolation
        in_range = np.unique(np.where(np.isfinite(cs(self.instrument_wavelengths)))[1])
        self.instrument_library_spectra = cs(self.instrument_wavelengths)[:, in_range]
        self.instrument_library_df = self.library_df.copy()
        # reassign the instrument data so the range matches the library
        self.instrument_wavelengths = self.instrument_wavelengths[in_range]
        self.spectral_input = self.spectral_input[:, in_range]

    def get_instrument_library(self):
        &#34;&#34;&#34;
        Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra at the same
            spectral space as the incoming spectral data.

        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        return self.instrument_library_df, self.instrument_library_spectra

    def make_average_instrument_library(self):
        &#34;&#34;&#34;
        This assumes that the spectral libraries contain mineral spectra. It groupsby the mineral names and produces an
            average spectrum for each mineral.

        Returns:
            Nothing: Sets the `internal average_instrument_library_spectra` and `average_instrument_library_df` variables

        &#34;&#34;&#34;
        grouped_dict = self.instrument_library_df.groupby(&#39;mineral&#39;).indices
        mean_spectra = []
        temp_df = pd.DataFrame()
        for val in grouped_dict:
            indices = grouped_dict[val]
            mean_spectra.append(np.mean(self.instrument_library_spectra[indices, :], axis=0))
            temp_df = temp_df.append(self.instrument_library_df.iloc[indices[0], :])
        temp_df = temp_df.reset_index(drop=True)

        self.average_instrument_library_spectra = np.asarray(mean_spectra)
        self.average_instrument_library_df = temp_df

    def get_average_instrument_library(self):
        &#34;&#34;&#34;
        Returns the instrument spectral library averages (grouped and averaged based on mineral name)

        Returns:
            Dataframe: The ancillary data associated with the spectral library
            ndarray: A numpy array of spectral data corresponding to the library

        &#34;&#34;&#34;
        if self.average_instrument_library_df is None:
            self.make_average_instrument_library()
        return self.average_instrument_library_df, self.average_instrument_library_spectra

    def tag_spectra_below_a_maximum_threshold(self, threshold=0.01, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            threshold ():
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        return np.max(inst_spec, axis=1) &lt; threshold

    def r2_error(self, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        synth = np.dot(self.nmf_results[0], self.nmf_results[1])

        # normalise the spectra
        synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

        # store the result and return them
        from scipy.stats import pearsonr
        r2 = [pearsonr(val1, val2)[0] for val1, val2 in zip(inst_spec, synthetics)]

        return np.asarray(r2)

    def rms_error(self, fit_to=&#39;full&#39;):
        &#34;&#34;&#34;

        Args:
            fit_to ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        synth = np.dot(self.nmf_results[0], self.nmf_results[1])

        # normalise the spectra
        synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

        # store the result and return them
        rms_error = np.sqrt(
            np.sum(np.square(inst_spec - synthetics), axis=1) / wavelengths.shape[0])
        return rms_error

    def fit(self, fit_to=&#39;full&#39;, solver=&#39;mu&#39;, threshold=1.e-4):
        &#34;&#34;&#34;

        Args:
            fit_to ():
            solver ():
            threshold ():

        Returns:

        &#34;&#34;&#34;
        # set the user spectral input
        if self.spectral_input is None:
            print(&#39;You need to enter input data to run the analysis &#39;)
            return 0

        if fit_to == &#39;culled&#39;:
            if self.culled_df is None:
                print(&#39;You need to cull something first&#39;)
                return 0

        # get the library &amp; instrument data
        _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

        # store what we performed the NMF on
        self.which_nmf = fit_to

        # normalise the spectra
        lib_spec, inst_spec = self._normalise_the_spectra(inst_spec, lib_spec)

        # do the NMF calculation
        if &#39;mu&#39; in solver:
            nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                                     n_components=lib_spec.shape[0], max_iter=600, solver=&#39;mu&#39;,
                                                    beta_loss=1, tol=1.e-5, random_state=42)
        else:
            nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                                 n_components=lib_spec.shape[0], max_iter=600, solver=&#39;cd&#39;,
                                                 beta_loss=2, random_state=42, tol=1.e-4)


        # apply a threshold to zero out ridiculously small values
        indices = np.where(nmf_results[0] &lt; threshold)
        nmf_results[0][indices] = 0.0

        # normalize the abundance values between 0 and 1
        part_one = nmf_results[0] / np.expand_dims(np.sum(nmf_results[0], axis=1), axis=1)

        # store the result and return them
        self.nmf_results = part_one, nmf_results[1]
        rms_error = self.rms_error(fit_to=fit_to)
        r2_error = self.r2_error(fit_to=fit_to)
        self.rms_fit_error = rms_error
        self.r2_fit_error = r2_error
        return part_one, nmf_results[1], rms_error, r2_error

    @staticmethod
    def _normalise_the_spectra(inst_spec, lib_spec):
        &#34;&#34;&#34;

        Args:
            inst_spec ():
            lib_spec ():

        Returns:

        &#34;&#34;&#34;
        lib_spec = normalize(lib_spec, norm=&#39;max&#39;, axis=1)
        inst_spec = normalize(inst_spec, norm=&#39;max&#39;, axis=1)
        return lib_spec, inst_spec

    def _hull_corrections(self, wavelengths, inst_spec, lib_spec, tir=False):
        &#34;&#34;&#34;

        Args:
            wavelengths ():
            inst_spec ():
            lib_spec ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        inst_hull = get_absorption(wavelengths, inst_spec, 2)
        if tir:
            lib_spec = get_absorption(wavelengths, 1.0 - lib_spec, self.hull_type)
            inst_spec = get_absorption(wavelengths, 1.0 - inst_spec, self.hull_type)
        else:
            lib_spec = get_absorption(wavelengths, lib_spec, self.hull_type)
            inst_spec = get_absorption(wavelengths, inst_spec, self.hull_type)

        lib_spec = np.nan_to_num(lib_spec)
        inst_spec = np.nan_to_num(inst_spec)
        lib_spec[lib_spec &lt; 0] = 0
        inst_spec[inst_spec &lt; 0] = 0

        return lib_spec, inst_spec, inst_hull

    def get_library_and_instrument_data(self, which_library):
        &#34;&#34;&#34;

        Args:
            which_library ():

        Returns:

        &#34;&#34;&#34;
        lib_df = None
        lib_spec = None
        range_index = self.range_indices

        inst_spec = self.spectral_input[:, range_index[0]:range_index[1]]
        if which_library == &#39;full&#39;:
            lib_df = self.instrument_library_df
            lib_spec = self.instrument_library_spectra[:, range_index[0]:range_index[1]]
        elif which_library == &#39;average&#39;:
            lib_df = self.average_instrument_library_df
            lib_spec = self.average_instrument_library_spectra[:, range_index[0]:range_index[1]]
        elif which_library == &#39;culled&#39;:
            lib_df = self.culled_df
            lib_spec = self.culled_spectra

        wavelengths = self.instrument_wavelengths[range_index[0]:range_index[1]]
        lib_spec[lib_spec &lt; 0] = 0
        inst_spec[inst_spec &lt; 0] = 0
        return lib_df, lib_spec, inst_spec, wavelengths

    def get_nmf_results(self):
        &#34;&#34;&#34;

        Returns:

        &#34;&#34;&#34;
        return self.nmf_results, self.which_nmf

    def plot_spectral_fit_at_ordinate(self, value, ordinates, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                          fill_between=True, mask=0, title=None, color=None, additional_label=&#39;&#39;, legend=True, return_contributions=False):
        &#34;&#34;&#34;

        Args:
            value ():
            ordinates ():
            plot_type ():
            what ():
            top ():
            total_contribution ():
            ax ():
            fill_between ():
            mask ():
            title ():
            color ():
            additional_label ():
            legend ():
            return_contributions ():

        Returns:

        &#34;&#34;&#34;
        ax = ax or plt.gca()
        # get the fit
        nmf = self.nmf_results
        df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

        if not np.isscalar(mask):
            index = np.square(ordinates - ordinates[mask][np.square(ordinates[mask] - value).argmin()]).argmin()
            rms = self.rms_fit_error[mask][index]
            r2 = self.r2_fit_error[mask][index]
        else:
            index = np.square(ordinates - value).argmin()
            rms = self.rms_fit_error[index]
            r2 = self.r2_fit_error[index]

        args = np.argsort(nmf[0][index, :])[-top:]
        top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
        contributions = np.round(np.flip(nmf[0][index, args]), 2)

        # get total contribution
        if total_contribution:
            grp = df.groupby(what).indices
            name = []
            amount = []
            for val in grp:
                name.append(val)
                amount.append(np.sum(nmf[0][index, grp[val]]))

            args = np.argsort(amount)[-top:]
            contributions = np.round(np.asarray(amount)[args], 2)
            top_minerals = np.asarray(name)[args]
        return_minerals = (top_minerals, contributions)

        # get the nmf interpretation of the spectrum and the actual spectrum
        synthetic_spectrum = nmf[0][index, :].dot(nmf[1])
        actual_spectrum = instrument_spectra[index, :]

        # 1: TIR = True : Only need a baseline correction to the actual spectra
        # 2: Hull = True : Only need to get the actual spectra hull removed
        hull = None
        sf = None
        temp_spectrum = None
        if self.tir:
            actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
            sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        if self.hull:
            hull = get_absorption(wavelengths, actual_spectrum, 2)
            temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
            sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

        if sf is None:
            scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        else:
            scale_factor = sf

        # now its only about the display
        # can either be reflectance or hull
        # tir can only be reflectance
        if self.tir:
            synthetic_spectrum = synthetic_spectrum * scale_factor
        else:
            if plot_type == &#39;ref&#39;:
                synthetic_spectrum = hull - synthetic_spectrum * scale_factor
            else:
                synthetic_spectrum = synthetic_spectrum * scale_factor
                actual_spectrum = temp_spectrum

        if top != 0:
            minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
            seperator = &#39;, &#39;
            label = seperator.join(minerals) + &#39;, RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label
        else:
            label = &#39;RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label

        # actual_spectrum += offset
        # synthetic_spectrum += offset
        if fill_between:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            if color:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
            else:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
            line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.3)
            line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.3)
        else:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            if color:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
            else:
                line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        ax.set_xlabel(&#39;Wavelength (nm)&#39;, fontsize=16)
        ax.set_ylabel(&#39;Reflectance&#39;, fontsize=16)
        if title:
            ax.set_title(title, fontsize=20)
        if legend:
            ax.legend()
        return wavelengths, actual_spectrum, synthetic_spectrum, return_minerals

    def plot_spectral_fit(self, index, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                          fill_between=True):
        &#34;&#34;&#34;

        Args:
            index ():
            plot_type ():
            what ():
            top ():
            total_contribution ():
            ax ():
            fill_between ():

        Returns:

        &#34;&#34;&#34;
        ax = ax or plt.gca()
        # get the fit
        nmf = self.nmf_results
        df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

        args = np.argsort(nmf[0][index, :])[-top:]
        top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
        contributions = np.round(np.flip(nmf[0][index, args]), 2)

        # get total contribution
        if total_contribution:
            grp = df.groupby(what).indices
            name = []
            amount = []
            for val in grp:
                name.append(val)
                amount.append(np.sum(nmf[0][index, grp[val]]))

            args = np.argsort(amount)[-top:]
            contributions = np.round(np.asarray(amount)[args], 2)
            top_minerals = np.asarray(name)[args]

        # get the nmf interpretation of the spectrum and the actual spectrum
        synthetic_spectrum = np.dot(nmf[0][index, :], nmf[1])
        actual_spectrum = instrument_spectra[index, :]

        # 1: TIR = True : Only need a baseline correction to the actual spectra
        # 2: Hull = True : Only need to get the actual spectra hull removed
        hull = None
        sf = None
        temp_spectrum = None
        if self.tir:
            actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
            sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        if self.hull:
            hull = get_absorption(wavelengths, actual_spectrum, 2)
            temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
            sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

        if sf is None:
            scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
        else:
            scale_factor = sf

        # now its only about the display
        # can either be reflectance or hull
        # tir can only be reflectance
        if self.tir:
            synthetic_spectrum = synthetic_spectrum * scale_factor
        else:
            if plot_type == &#39;ref&#39;:
                synthetic_spectrum = hull - synthetic_spectrum * scale_factor
            else:
                synthetic_spectrum = synthetic_spectrum * scale_factor
                actual_spectrum = temp_spectrum

        minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
        seperator = &#39; + &#39;
        label = seperator.join(minerals)

        if fill_between:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
            line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.5)
            line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                    where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.5)
        else:
            line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        ax.set_xlabel(&#39;Wavelength (nm)&#39;)
        ax.set_ylabel(&#39;Reflectance&#39;)
        ax.legend()
        return wavelengths, actual_spectrum, synthetic_spectrum

    def cull_by_rank(self, rank=10, direction=&#39;gt&#39;):
        &#34;&#34;&#34;

        Args:
            rank ():
            direction ():

        Returns:

        &#34;&#34;&#34;
        # cut out the last rank nmf results above or below e.g. cut the top 10 out top_or_bottom_cut(rank=10, direction=&#39;above)
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(np.sum(self.nmf_results[0], axis=0))
        orders = np.argsort(proportions)
        which_nmf = self.which_nmf

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)
        temp_df = temp_df.iloc[orders, :]
        temp_spectra = temp_spectra[orders, :]
        self.which_culled = which_nmf

        if direction.lower() == &#39;gt&#39;:
            temp_df = temp_df.iloc[-rank:, :].reset_index(drop=True)
            temp_spectra = temp_spectra[-rank:, :]
        else:
            temp_df = temp_df.iloc[:rank, :].reset_index(drop=True)
            temp_spectra = temp_spectra[:rank, :]

        self.cull_type = &#39;top_or_bottom_&#39; + direction
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        return self.fit(fit_to=&#39;culled&#39;)

    def keep_library_above(self, threshold=0.0):
        &#34;&#34;&#34;

        Args:
            threshold ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            self.which_nmf = &#39;full&#39;
            # print(&#39;You need to fit some data first&#39;)
            # return ()

        # see what the last nmf results were generated from
        which_nmf = self.which_nmf
        temp_df, temp_spectra, _, wavelengths = self.get_library_and_instrument_data(which_nmf)

        # do a hull correction if asked for
        if self.hull or self.tir:
            lib_spec, _, _ = self._hull_corrections(wavelengths, temp_spectra, temp_spectra, self.tir)

        indices = np.where(np.max(lib_spec, axis=1) &gt; threshold)[0]

        return self.keep_specific(keep_these=indices, indices_supplied=True)

    def keep_specific(self, keep_these=None, indices_supplied=False, keep_type=&#39;mineral&#39;):
        &#34;&#34;&#34;

        Args:
            keep_these ():
            indices_supplied ():
            keep_type ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            self.which_nmf = &#39;full&#39;
            # print(&#39;You need to fit some data first&#39;)
            # return ()

        # see what the last nmf results were generated from
        which_nmf = self.which_nmf
        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

        self.which_culled = which_nmf
        self.cull_type = &#39;grouped_&#39; + keep_type
        # first find out where the stuff is in the df so we can flag which spectra to drop as well
        if not indices_supplied:
            indices = temp_df[temp_df[keep_type].str.contains(&#39;|&#39;.join(keep_these))].index.values
        else:
            indices = keep_these

        if len(indices) &gt; 0:
            temp_df = temp_df.iloc[indices, :].reset_index(drop=True)
            temp_spectra = temp_spectra[indices, :]
            self.culled_df = temp_df
            self.culled_spectra = temp_spectra
            return self.fit(fit_to=&#39;culled&#39;)

    def drop_specific(self, drop_these=None, indices_supplied=False, drop_type=&#39;mineral&#39;, solver=&#39;mu&#39;):
        &#34;&#34;&#34;

        Args:
            drop_these ():
            indices_supplied ():
            drop_type ():
            solver ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            which_nmf = &#39;full&#39;
        else:
            # see what the last nmf results were generated from
            which_nmf = self.which_nmf

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

        self.which_culled = which_nmf
        self.cull_type = &#39;grouped_&#39; + drop_type
        # first find out where the stuff is in the df so we can flag which spectra to drop as well
        if not indices_supplied:
            indices = temp_df[temp_df[drop_type].str.contains(&#39;|&#39;.join(drop_these))].index.values
        else:
            indices = drop_these

        if len(indices) &gt; 0:
            temp_df = temp_df.drop(indices, axis=0).reset_index(drop=True)
            temp_spectra = np.delete(temp_spectra, indices, axis=0)
            self.culled_df = temp_df
            self.culled_spectra = temp_spectra
            return self.fit(fit_to=&#39;culled&#39;, solver=solver)

    def cull_by_individual_and_total_sample_contribution(self, cull_value1=None, cull_value2=None):
        &#34;&#34;&#34;

        Args:
            cull_value1 ():
            cull_value2 ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_nmf = self.nmf_results[0]
        if cull_value1:
            cull_value1 = cull_value1 / 100.0
        else:
            cull_value1 = 1.0 / temp_nmf.shape[1]

        if cull_value2:
            cull_value2 = cull_value2 / 100.0
        else:
            cull_value2 = 1.0 / temp_nmf.shape[1]

        args = np.where(temp_nmf &lt; cull_value1)
        temp_nmf[args[0], args[1]] = 0
        # now we add them up as a function of the number of samples
        sample_sum = np.sum(temp_nmf, axis=0) / temp_nmf.shape[0]
        args = np.where(sample_sum &gt; cull_value2)[0]

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)
        temp_spectra = temp_spectra[args, :]

        # store the culled data frame and spectral data and rerun the unmixing
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        self.which_culled = self.which_nmf

        self.cull_type = &#39;double_cull_&#39;  # + str(cull_value)
        return self.fit(fit_to=&#39;culled&#39;)

    def cull_by_cumulative_proportion(self, cull_value=10, direction=&#39;gt&#39;, cumulative=True):
        &#34;&#34;&#34;

        Args:
            cull_value ():
            direction ():
            cumulative ():

        Returns:

        &#34;&#34;&#34;
        # cut the last NMF result at some % proportion as either gt or lt
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, temp_spectra, temp_nmf = self.cull_entries(cumulative, direction, cull_value)

        # store the culled data frame and spectral data and rerun the unmixing
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        self.which_culled = self.which_nmf

        self.cull_type = &#39;proportion_&#39; + direction + str(cull_value)
        return self.fit(fit_to=&#39;culled&#39;)

    def cull_entries(self, cumulative, direction, proportion):
        &#34;&#34;&#34;

        Args:
            cumulative ():
            direction ():
            proportion ():

        Returns:

        &#34;&#34;&#34;
        # these are the individual spectral sample proportions in the library
        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        # set them from low to high
        orders = np.argsort(proportions)
        props = proportions[orders]

        temp_nmf = self.nmf_results
        t1 = temp_nmf[0][:, orders]
        t2 = temp_nmf[1][orders, :]
        temp_nmf = [t1, t2]

        temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
        temp_df = temp_df.iloc[orders, :].reset_index(drop=True)
        temp_spectra = temp_spectra[orders, :]

        cutoff_index = self._proportion_cutoff_indices(direction, proportion, props, cumulative=cumulative)
        temp_df = temp_df.iloc[cutoff_index, :].reset_index(drop=True)
        temp_spectra = temp_spectra[cutoff_index, :]
        t1 = temp_nmf[0][:, cutoff_index]
        t2 = temp_nmf[1][cutoff_index, :]
        temp_nmf = [t1, t2]
        return temp_df, temp_spectra, temp_nmf

    @staticmethod
    def _proportion_cutoff_indices(direction, proportion, props, cumulative=True):
        &#34;&#34;&#34;

        Args:
            direction ():
            proportion ():
            props ():
            cumulative ():

        Returns:

        &#34;&#34;&#34;
        if cumulative:
            if direction.lower() == &#39;gt&#39;:
                cutoff_index = np.where(np.cumsum(props) &gt;= proportion)[0]
            else:
                cutoff_index = np.where(np.cumsum(props) &lt;= proportion)[0]
            if len(cutoff_index) == 0:
                cutoff_index = range(props.shape[0])
        else:
            if direction.lower() == &#39;gt&#39;:
                cutoff_index = np.where(props &gt;= proportion)[0]
            else:
                cutoff_index = np.where(props &lt;= proportion)[0]
            if len(cutoff_index) == 0:
                cutoff_index = range(props.shape[0])

        return cutoff_index

    def plot_proportions(self, plot_what=&#39;mineral&#39;, stacked=True):
        &#34;&#34;&#34;

        Args:
            plot_what ():
            stacked ():

        Returns:

        &#34;&#34;&#34;
        # plot the proportions of the last NMF run
        # todo return the axes and the figure so people can put it where they want
        # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
        # your call

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        orders = np.argsort(proportions)
        props = proportions[orders]
        names = None

        which_nmf = self.which_nmf
        if which_nmf.lower() == &#39;full&#39;:
            names = self.instrument_library_df[plot_what].iloc[orders]
        elif which_nmf.lower() == &#39;average&#39;:
            names = self.average_instrument_library_df[plot_what].iloc[orders]
        elif which_nmf == &#39;culled&#39;:
            names = self.culled_df[plot_what].iloc[orders]

        # make a temporary data frame
        temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
        # todo allow people to change the color map
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if stacked:
            temp_df.plot.bar(stacked=True, legend=False, color=colors)
            # todo work out how many cols are needed based on len(names) and adjust accordingly
            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
            plt.subplots_adjust(right=0.55)
        else:
            plt.bar(np.arange(props.shape[0]), props, tick_label=names, color=colors)
            plt.xticks(rotation=90)
            plt.tight_layout()
        plt.show()

    def cull_by_grouped(self, cull_value=0.0, grouping=&#39;mineral&#39;):
        &#34;&#34;&#34;

        Args:
            cull_value ():
            grouping ():

        Returns:

        &#34;&#34;&#34;
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        _, names, props = self._group_and_sort_by_proportion(grouping)

        # see what values are below this &amp; drop them
        cull_this = np.where(props &lt;= cull_value)[0]
        if len(cull_this) &gt; 0:
            names = names[cull_this]
            return self.drop_specific(drop_these=names, drop_type=grouping)
        else:
            return 0

    def plot_grouped_proportions(self, group=None, stacked=True, ax=None):
        &#34;&#34;&#34;

        Args:
            group ():
            stacked ():
            ax ():

        Returns:

        &#34;&#34;&#34;
        if group is None:
            group = [&#39;mineral&#39;]
        ax = ax or plt.gca()
        # plot the proportions of the last NMF run
        # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
        # your call

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        cum_sum, names, props = self._group_and_sort_by_proportion(group)

        temp = []
        for index, name in enumerate(names):
            temp.append(name + &#39;|&#39; + str(np.round(props[index], 2)) + &#39;|&#39; + str(np.round(cum_sum[index], 2)))

        names = list(np.asarray(temp))

        # make a temporary data frame
        temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
        # todo allow people to change the color map
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))

        if len(group) &gt; 1:
            stacked = True
        if stacked:
            temp_df.plot.bar(stacked=True, legend=False, color=colors)
            # todo work out how many cols are needed based on len(names) and adjust accordingly
            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
            plt.subplots_adjust(right=0.4)
        else:
            plt.bar(names, props, color=colors)
            plt.xticks(rotation=90)
            plt.tight_layout()

        plt.show()

    def _group_and_sort_by_proportion(self, group):
        &#34;&#34;&#34;

        Args:
            group ():

        Returns:

        &#34;&#34;&#34;
        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
        minerals_grouped = temp_df.groupby(group).indices
        names = []
        proportion = []
        for val in minerals_grouped:
            names.append(val)
            proportion.append(np.sum(proportions[minerals_grouped[val]]))
        orders = np.argsort(proportion)
        props = np.asarray(proportion)[orders]
        names = np.asarray(names)[orders]
        cumsum = np.cumsum(props)
        return cumsum, names, props

    def plot_stacked_weight(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=1, ax=None, legend_ax=None,
                            do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                            mask=0, title=&#34;Relative Mineral Proportions&#34;, xtitle=&#39;Depth (m)&#39;):
        &#34;&#34;&#34;

        Args:
            x_ordinate ():
            what_thing ():
            partitions ():
            ax ():
            legend_ax ():
            do_plotly ():
            save_name ():
            hide_value ():
            use_tsg_colors ():
            mask ():
            title ():
            xtitle ():

        Returns:

        &#34;&#34;&#34;
        if do_plotly is False:
            ax = ax or plt.gca()
            legend_ax = legend_ax or plt.gca()

        # plot the stacked weights from the last NMF run
        # which_nmf determines where the last result came from
        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
        temp_weights = self.nmf_results[0].copy()
        temp_weights = temp_weights[:, args]
        names = np.unique(temp_df[what_thing].iloc[args])
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)

        # todo add in the nmf_results[1] into the mix so it can be passed back
        new_weight = []
        # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
        # mineral name todo change this a pandas groupby and indices call instead
        for name in names:
            args = np.where(temp_df[what_thing] == name)[0]
            new_weight.append(np.sum(temp_weights[:, args], axis=1))
        new_weight = np.transpose(np.asarray(new_weight))
        new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

        # find where the indices are that will let us split the data according to the user partition size
        split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
        if np.isscalar(mask):
            mask = np.ones(x_ordinate.shape).astype(bool)

        x_ordinate_split = np.split(x_ordinate, split_locations)
        new_weight_split = np.split(new_weight, split_locations)
        mask_split = np.split(mask, split_locations)

        depth = []
        width = []
        weight = []

        count = 0
        if np.min(np.diff(x_ordinate)) &lt; partitions:
            for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
                if xval.shape[0] &gt; 0:
                    depth.append(xval[0])
                    width.append(xval[-1]-xval[0])
                    any_masked = float(np.where(mask_val)[0].shape[0])
                    # if nothing is masked then dont average
                    if any_masked &gt; 0:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                    else:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0))
        else:
            depth = x_ordinate
            width = np.zeros((depth.shape[0])) + partitions
            weight = new_weight[mask]

        weight = np.asarray(weight)
        depth = np.asarray(depth)
        width = np.asarray(width)

        tdepth = [str(int(val)) for val in depth]
        new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if not do_plotly:
            new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
        else:
            if hide_value &gt; 0:
                args = np.where(weight &lt; hide_value)
                weight[args[0], args[1]] = np.nan
                # normalize
                weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

            data = []
            for var in np.arange(weight.shape[1]):
                if what_thing == &#39;mineral&#39;:
                    thing = &#39;Mineral&#39;
                elif what_thing == &#39;group&#39;:
                    thing = &#39;Group&#39;
                else:
                    use_tsg_colors = False

            color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours.csv&#34;)
            for val in np.unique(temp_df[&#39;group&#39;]):
                unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
                number_of_minerals = unique_minerals.shape[0]
                group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
                # lets get alpha values
                rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
                alphas = np.linspace(1.0, 0.5, number_of_minerals)
                # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
                # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
                # rgb = rgb.astype(int)
                for index, mineral in enumerate(unique_minerals):
                    #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                    color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                    location = np.where(names == mineral)[0][0]
                    data.append(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                         marker_color=color))

            fig = go.Figure(data=data)
            # Change the bar mode
            # todo put in keywords for titles and labels
            title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
            fig.update_layout(barmode=&#39;stack&#39;, title=title, xaxis_title=xtitle,
                              yaxis_title=&#34;Relative Proportion&#34;, legend_orientation=&#34;h&#34;, font_size=20)
            fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
            fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
            fig.write_html(save_name+&#34;.html&#34;)

        return names, depth, np.nan_to_num(weight, 0)

    def plot_stacked_weight_hack(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=100, ax=None, legend_ax=None,
                            do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                            mask=0, title=&#34;Relative Mineral Proportions&#34;):
        &#34;&#34;&#34;

        Args:
            x_ordinate ():
            what_thing ():
            partitions ():
            ax ():
            legend_ax ():
            do_plotly ():
            save_name ():
            hide_value ():
            use_tsg_colors ():
            mask ():
            title ():

        Returns:

        &#34;&#34;&#34;

        if do_plotly is False:
            ax = ax or plt.gca()
            legend_ax = legend_ax or plt.gca()

        if self.nmf_results is None:
            print(&#39;You need to fit some data first&#39;)
            return ()

        temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
        args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
        temp_weights = self.nmf_results[0].copy()[:, args]
        names = np.unique(temp_df[what_thing].iloc[args])
        temp_df = temp_df.iloc[args, :].reset_index(drop=True)

        new_weight = []
        # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
        # mineral name todo change this a pandas groupby and indices call instead
        for name in names:
            args = np.where(temp_df[what_thing] == name)[0]
            new_weight.append(np.sum(temp_weights[:, args], axis=1))
        new_weight = np.transpose(np.asarray(new_weight))
        new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

        # find where the indices are that will let us split the data according to the user partition size
        split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
        if np.isscalar(mask):
            mask = np.ones(x_ordinate.shape).astype(bool)

        x_ordinate_split = np.split(x_ordinate, split_locations)
        new_weight_split = np.split(new_weight, split_locations)
        mask_split = np.split(mask, split_locations)

        depth = []
        width = []
        weight = []

        count=0
        if np.min(np.diff(x_ordinate)) &lt; partitions:
            for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
                if xval.shape[0] &gt; 0:
                    depth.append(xval[0])
                    width.append(xval[-1]-xval[0])
                    any_masked = float(np.where(mask_val)[0].shape[0])
                    # if nothing is masked then dont average
                    if any_masked &gt; 0:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                    else:
                        weight.append(np.sum(weight_val[mask_val, :], axis=0))
        else:
            depth = x_ordinate
            width = np.zeros((depth.shape[0])) + partitions
            weight = new_weight[mask]

        weight = np.asarray(weight)
        depth = np.asarray(depth)
        width = np.asarray(width)

        tdepth = [str(int(val)) for val in depth]
        new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
        colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
        if not do_plotly:
            new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
        else:
            if hide_value &gt; 0:
                args = np.where(weight &lt; hide_value)
                weight[args[0], args[1]] = np.nan
                # normalize
                weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

            from plotly.subplots import make_subplots
            fig = make_subplots(rows=3, cols=1, #shared_xaxes=True,
                                specs=[[{}], [{&#34;rowspan&#34;:2}], [None]])

            # todo add in a bit for group plots not just mineral
            data = []
            color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours_mkII.csv&#34;)
            for val in np.unique(temp_df[&#39;group&#39;]):
                unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
                number_of_minerals = unique_minerals.shape[0]
                group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
                # lets get alpha values
                rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
                alphas = np.linspace(1.0, 0.5, number_of_minerals)
                # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
                # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
                # rgb = rgb.astype(int)
                for index, mineral in enumerate(unique_minerals):
                    #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                    color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                    location = np.where(names == mineral)[0][0]
                    fig.add_trace(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                         marker_color=color), row=2, col=1)

            # MSDP11 HACK
            msdp11_df = pd.read_csv(&#39;msdp11_log.csv&#39;)
            lithology = msdp11_df.columns.values[2:]
            x = msdp11_df[&#39;X&#39;].values.astype(int)
            w = msdp11_df[&#39;Width&#39;].values.astype(int)
            colors=[&#34;brown&#34;, &#34;saddlebrown&#34;, &#34;lightyellow&#34;, &#34;pink&#34;, &#34;red&#34;, &#34;skyblue&#34;, &#34;olivedrab&#34;, &#34;darkgray&#34;, &#34;gray&#34;, &#34;indianred&#34;, &#34;purple&#34;]

            for index, var in enumerate(lithology):
                y = msdp11_df[var].values
                fig.add_trace(go.Bar(name=var, x=x+w/2, y=y, width=w, marker_color=colors[index]), row=1, col=1)

            # Change the bar mode
            # todo put in keywords for titles and labels
            title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
            fig.update_layout(barmode=&#39;stack&#39;, title=title, legend_orientation=&#34;h&#34;, font_size=20)
            fig.update_yaxes(showticklabels=False, row=1, col=1)
            fig.update_xaxes(title_text=&#39;Depth (m)&#39;, row=2, col=1)
            fig.update_yaxes(title_text=&#39;Relative Proportion&#39;, row=2, col=1)
            fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
            fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
            fig.write_html(save_name+&#34;.html&#34;)

        return names, depth, np.nan_to_num(weight, 0)

    def plot_library_spectra(self, search_item=&#39;mineral&#39;, names=None, plot_hull=False, tir=False):
        &#34;&#34;&#34;

        Args:
            search_item ():
            names ():
            plot_hull ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        if names is None:
            return 0
        df = self.instrument_library_df
        wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
        spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]
        if plot_hull:
            if tir:
                spectra = get_absorption(wavelengths, 1.0 - spectra, 1)
            else:
                spectra = get_absorption(wavelengths, spectra, 1)

        indices = df.loc[df[search_item].isin(names)].index.values
        if len(indices) &gt; 0:
            for val in indices:
                plt.plot(wavelengths, spectra[val, :], label=df[search_item].iloc[val])
            plt.legend()
            plt.show()

    def compare_instrument_spectra_to_specific(self, index, search_type=&#39;mineral&#39;, search_item=&#39;kaolinite&#39;, hull=False,
                                               normalise=False):
        &#34;&#34;&#34;

        Args:
            index ():
            search_type ():
            search_item ():
            hull ():
            normalise ():

        Returns:

        &#34;&#34;&#34;
        df = self.instrument_library_df
        wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
        spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]

        instrument_data = self.spectral_input[index, self.range_indices[0]:self.range_indices[1]]
        if hull:
            instrument_data = get_absorption(wavelengths, instrument_data, 1)
        if normalise:
            instrument_data = instrument_data / np.max(instrument_data)

        indices = np.where(df[search_type].str.contains(search_item))[0]
        if len(indices) &gt; 0:
            plt.plot(wavelengths, instrument_data, label=&#39;Instrument&#39;, color=&#39;k&#39;)
            for val in indices:
                spectrum = spectra[val, :]
                if hull:
                    spectrum = get_absorption(wavelengths, spectrum, 1)
                if normalise:
                    spectrum = spectrum / np.max(spectrum)
                plt.plot(wavelengths, spectrum, label=df[search_type].iloc[val])
            plt.legend()
            plt.show()

    def mixtures(self, which_library=&#39;full&#39;, tir=False):
        &#34;&#34;&#34;
        
        Args:
            which_library ():
            tir ():

        Returns:

        &#34;&#34;&#34;
        # singleton
        lib_df, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(which_library)
        lib_spec, inst_spec, inst_hull = self._hull_corrections(wavelengths, inst_spec, lib_spec, tir=tir)

        # get all of the possible combinations of the end members up to a max mixture level e.g 1 through to 4
        lib_elements = list(np.arange(lib_spec.shape[0]))
        mixtures = []
        max_mixture_level = 4 # hard coded for trial
        for val in range(1, max_mixture_level+1):
            mixtures.append(list(combinations(lib_elements, val)))

        # run the NMF to calculate the weights for the potential mixture levels
        rms_error = []
        for val in mixtures[0]:
            nmf_results = non_negative_factorization(inst_spec, H=np.reshape(lib_spec[val[1], :], [1, -1]),
                                                     update_H=False, init=None,
                                                     n_components=2, max_iter=600, solver=&#39;mu&#39;,
                                                     beta_loss=1, tol=1.e-4, random_state=42)[:2]
            rms_error.append(np.sqrt(np.sum(np.square(np.dot(nmf_results[0][0], nmf_results[0][1]) - inst_spec), axis=1)))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="spex.speclib.speclib.SpectralMix.compare_instrument_spectra_to_specific"><code class="name flex">
<span>def <span class="ident">compare_instrument_spectra_to_specific</span></span>(<span>self, index, search_type='mineral', search_item='kaolinite', hull=False, normalise=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>index ():
search_type ():
search_item ():
hull ():
normalise ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_instrument_spectra_to_specific(self, index, search_type=&#39;mineral&#39;, search_item=&#39;kaolinite&#39;, hull=False,
                                           normalise=False):
    &#34;&#34;&#34;

    Args:
        index ():
        search_type ():
        search_item ():
        hull ():
        normalise ():

    Returns:

    &#34;&#34;&#34;
    df = self.instrument_library_df
    wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
    spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]

    instrument_data = self.spectral_input[index, self.range_indices[0]:self.range_indices[1]]
    if hull:
        instrument_data = get_absorption(wavelengths, instrument_data, 1)
    if normalise:
        instrument_data = instrument_data / np.max(instrument_data)

    indices = np.where(df[search_type].str.contains(search_item))[0]
    if len(indices) &gt; 0:
        plt.plot(wavelengths, instrument_data, label=&#39;Instrument&#39;, color=&#39;k&#39;)
        for val in indices:
            spectrum = spectra[val, :]
            if hull:
                spectrum = get_absorption(wavelengths, spectrum, 1)
            if normalise:
                spectrum = spectrum / np.max(spectrum)
            plt.plot(wavelengths, spectrum, label=df[search_type].iloc[val])
        plt.legend()
        plt.show()</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.convert_library_to_instrument"><code class="name flex">
<span>def <span class="ident">convert_library_to_instrument</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the internal spectral library to the same spectral domain as the spectral data that is to be analysed.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>Sets internal variables</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_library_to_instrument(self):
    &#34;&#34;&#34;
    Converts the internal spectral library to the same spectral domain as the spectral data that is to be analysed.

    Returns:
        Nothing: Sets internal variables

    &#34;&#34;&#34;
    cs = CubicSpline(self.library_wavelengths, self.library_spectra, extrapolate=False, axis=1)
    # want to exclude any wavelengths that required extrapolation
    in_range = np.unique(np.where(np.isfinite(cs(self.instrument_wavelengths)))[1])
    self.instrument_library_spectra = cs(self.instrument_wavelengths)[:, in_range]
    self.instrument_library_df = self.library_df.copy()
    # reassign the instrument data so the range matches the library
    self.instrument_wavelengths = self.instrument_wavelengths[in_range]
    self.spectral_input = self.spectral_input[:, in_range]</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.cull_by_cumulative_proportion"><code class="name flex">
<span>def <span class="ident">cull_by_cumulative_proportion</span></span>(<span>self, cull_value=10, direction='gt', cumulative=True)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>cull_value ():
direction ():
cumulative ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cull_by_cumulative_proportion(self, cull_value=10, direction=&#39;gt&#39;, cumulative=True):
    &#34;&#34;&#34;

    Args:
        cull_value ():
        direction ():
        cumulative ():

    Returns:

    &#34;&#34;&#34;
    # cut the last NMF result at some % proportion as either gt or lt
    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    temp_df, temp_spectra, temp_nmf = self.cull_entries(cumulative, direction, cull_value)

    # store the culled data frame and spectral data and rerun the unmixing
    self.culled_df = temp_df
    self.culled_spectra = temp_spectra
    self.which_culled = self.which_nmf

    self.cull_type = &#39;proportion_&#39; + direction + str(cull_value)
    return self.fit(fit_to=&#39;culled&#39;)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.cull_by_grouped"><code class="name flex">
<span>def <span class="ident">cull_by_grouped</span></span>(<span>self, cull_value=0.0, grouping='mineral')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>cull_value ():
grouping ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cull_by_grouped(self, cull_value=0.0, grouping=&#39;mineral&#39;):
    &#34;&#34;&#34;

    Args:
        cull_value ():
        grouping ():

    Returns:

    &#34;&#34;&#34;
    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    _, names, props = self._group_and_sort_by_proportion(grouping)

    # see what values are below this &amp; drop them
    cull_this = np.where(props &lt;= cull_value)[0]
    if len(cull_this) &gt; 0:
        names = names[cull_this]
        return self.drop_specific(drop_these=names, drop_type=grouping)
    else:
        return 0</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.cull_by_individual_and_total_sample_contribution"><code class="name flex">
<span>def <span class="ident">cull_by_individual_and_total_sample_contribution</span></span>(<span>self, cull_value1=None, cull_value2=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>cull_value1 ():
cull_value2 ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cull_by_individual_and_total_sample_contribution(self, cull_value1=None, cull_value2=None):
    &#34;&#34;&#34;

    Args:
        cull_value1 ():
        cull_value2 ():

    Returns:

    &#34;&#34;&#34;
    # cut the last NMF result at some % proportion as either gt or lt
    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    temp_nmf = self.nmf_results[0]
    if cull_value1:
        cull_value1 = cull_value1 / 100.0
    else:
        cull_value1 = 1.0 / temp_nmf.shape[1]

    if cull_value2:
        cull_value2 = cull_value2 / 100.0
    else:
        cull_value2 = 1.0 / temp_nmf.shape[1]

    args = np.where(temp_nmf &lt; cull_value1)
    temp_nmf[args[0], args[1]] = 0
    # now we add them up as a function of the number of samples
    sample_sum = np.sum(temp_nmf, axis=0) / temp_nmf.shape[0]
    args = np.where(sample_sum &gt; cull_value2)[0]

    temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
    temp_df = temp_df.iloc[args, :].reset_index(drop=True)
    temp_spectra = temp_spectra[args, :]

    # store the culled data frame and spectral data and rerun the unmixing
    self.culled_df = temp_df
    self.culled_spectra = temp_spectra
    self.which_culled = self.which_nmf

    self.cull_type = &#39;double_cull_&#39;  # + str(cull_value)
    return self.fit(fit_to=&#39;culled&#39;)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.cull_by_rank"><code class="name flex">
<span>def <span class="ident">cull_by_rank</span></span>(<span>self, rank=10, direction='gt')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>rank ():
direction ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cull_by_rank(self, rank=10, direction=&#39;gt&#39;):
    &#34;&#34;&#34;

    Args:
        rank ():
        direction ():

    Returns:

    &#34;&#34;&#34;
    # cut out the last rank nmf results above or below e.g. cut the top 10 out top_or_bottom_cut(rank=10, direction=&#39;above)
    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(np.sum(self.nmf_results[0], axis=0))
    orders = np.argsort(proportions)
    which_nmf = self.which_nmf

    temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)
    temp_df = temp_df.iloc[orders, :]
    temp_spectra = temp_spectra[orders, :]
    self.which_culled = which_nmf

    if direction.lower() == &#39;gt&#39;:
        temp_df = temp_df.iloc[-rank:, :].reset_index(drop=True)
        temp_spectra = temp_spectra[-rank:, :]
    else:
        temp_df = temp_df.iloc[:rank, :].reset_index(drop=True)
        temp_spectra = temp_spectra[:rank, :]

    self.cull_type = &#39;top_or_bottom_&#39; + direction
    self.culled_df = temp_df
    self.culled_spectra = temp_spectra
    return self.fit(fit_to=&#39;culled&#39;)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.cull_entries"><code class="name flex">
<span>def <span class="ident">cull_entries</span></span>(<span>self, cumulative, direction, proportion)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>cumulative ():
direction ():
proportion ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cull_entries(self, cumulative, direction, proportion):
    &#34;&#34;&#34;

    Args:
        cumulative ():
        direction ():
        proportion ():

    Returns:

    &#34;&#34;&#34;
    # these are the individual spectral sample proportions in the library
    proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
    # set them from low to high
    orders = np.argsort(proportions)
    props = proportions[orders]

    temp_nmf = self.nmf_results
    t1 = temp_nmf[0][:, orders]
    t2 = temp_nmf[1][orders, :]
    temp_nmf = [t1, t2]

    temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(self.which_nmf.lower())
    temp_df = temp_df.iloc[orders, :].reset_index(drop=True)
    temp_spectra = temp_spectra[orders, :]

    cutoff_index = self._proportion_cutoff_indices(direction, proportion, props, cumulative=cumulative)
    temp_df = temp_df.iloc[cutoff_index, :].reset_index(drop=True)
    temp_spectra = temp_spectra[cutoff_index, :]
    t1 = temp_nmf[0][:, cutoff_index]
    t2 = temp_nmf[1][cutoff_index, :]
    temp_nmf = [t1, t2]
    return temp_df, temp_spectra, temp_nmf</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.drop_specific"><code class="name flex">
<span>def <span class="ident">drop_specific</span></span>(<span>self, drop_these=None, indices_supplied=False, drop_type='mineral', solver='mu')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>drop_these ():
indices_supplied ():
drop_type ():
solver ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def drop_specific(self, drop_these=None, indices_supplied=False, drop_type=&#39;mineral&#39;, solver=&#39;mu&#39;):
    &#34;&#34;&#34;

    Args:
        drop_these ():
        indices_supplied ():
        drop_type ():
        solver ():

    Returns:

    &#34;&#34;&#34;
    # cut the last NMF result at some % proportion as either gt or lt
    if self.nmf_results is None:
        which_nmf = &#39;full&#39;
    else:
        # see what the last nmf results were generated from
        which_nmf = self.which_nmf

    temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

    self.which_culled = which_nmf
    self.cull_type = &#39;grouped_&#39; + drop_type
    # first find out where the stuff is in the df so we can flag which spectra to drop as well
    if not indices_supplied:
        indices = temp_df[temp_df[drop_type].str.contains(&#39;|&#39;.join(drop_these))].index.values
    else:
        indices = drop_these

    if len(indices) &gt; 0:
        temp_df = temp_df.drop(indices, axis=0).reset_index(drop=True)
        temp_spectra = np.delete(temp_spectra, indices, axis=0)
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        return self.fit(fit_to=&#39;culled&#39;, solver=solver)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, fit_to='full', solver='mu', threshold=0.0001)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>fit_to ():
solver ():
threshold ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, fit_to=&#39;full&#39;, solver=&#39;mu&#39;, threshold=1.e-4):
    &#34;&#34;&#34;

    Args:
        fit_to ():
        solver ():
        threshold ():

    Returns:

    &#34;&#34;&#34;
    # set the user spectral input
    if self.spectral_input is None:
        print(&#39;You need to enter input data to run the analysis &#39;)
        return 0

    if fit_to == &#39;culled&#39;:
        if self.culled_df is None:
            print(&#39;You need to cull something first&#39;)
            return 0

    # get the library &amp; instrument data
    _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

    # do a hull correction if asked for
    if self.hull or self.tir:
        lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

    # store what we performed the NMF on
    self.which_nmf = fit_to

    # normalise the spectra
    lib_spec, inst_spec = self._normalise_the_spectra(inst_spec, lib_spec)

    # do the NMF calculation
    if &#39;mu&#39; in solver:
        nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                                 n_components=lib_spec.shape[0], max_iter=600, solver=&#39;mu&#39;,
                                                beta_loss=1, tol=1.e-5, random_state=42)
    else:
        nmf_results = non_negative_factorization(inst_spec, H=lib_spec, update_H=False, init=None,
                                             n_components=lib_spec.shape[0], max_iter=600, solver=&#39;cd&#39;,
                                             beta_loss=2, random_state=42, tol=1.e-4)


    # apply a threshold to zero out ridiculously small values
    indices = np.where(nmf_results[0] &lt; threshold)
    nmf_results[0][indices] = 0.0

    # normalize the abundance values between 0 and 1
    part_one = nmf_results[0] / np.expand_dims(np.sum(nmf_results[0], axis=1), axis=1)

    # store the result and return them
    self.nmf_results = part_one, nmf_results[1]
    rms_error = self.rms_error(fit_to=fit_to)
    r2_error = self.r2_error(fit_to=fit_to)
    self.rms_fit_error = rms_error
    self.r2_fit_error = r2_error
    return part_one, nmf_results[1], rms_error, r2_error</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.get_average_instrument_library"><code class="name flex">
<span>def <span class="ident">get_average_instrument_library</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the instrument spectral library averages (grouped and averaged based on mineral name)</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dataframe</code></dt>
<dd>The ancillary data associated with the spectral library</dd>
<dt><code>ndarray</code></dt>
<dd>A numpy array of spectral data corresponding to the library</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_average_instrument_library(self):
    &#34;&#34;&#34;
    Returns the instrument spectral library averages (grouped and averaged based on mineral name)

    Returns:
        Dataframe: The ancillary data associated with the spectral library
        ndarray: A numpy array of spectral data corresponding to the library

    &#34;&#34;&#34;
    if self.average_instrument_library_df is None:
        self.make_average_instrument_library()
    return self.average_instrument_library_df, self.average_instrument_library_spectra</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.get_instrument_library"><code class="name flex">
<span>def <span class="ident">get_instrument_library</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra at the same
spectral space as the incoming spectral data.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dataframe</code></dt>
<dd>The ancillary data associated with the spectral library</dd>
<dt><code>ndarray</code></dt>
<dd>A numpy array of spectral data corresponding to the library</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_instrument_library(self):
    &#34;&#34;&#34;
    Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra at the same
        spectral space as the incoming spectral data.

    Returns:
        Dataframe: The ancillary data associated with the spectral library
        ndarray: A numpy array of spectral data corresponding to the library

    &#34;&#34;&#34;
    return self.instrument_library_df, self.instrument_library_spectra</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.get_library"><code class="name flex">
<span>def <span class="ident">get_library</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dataframe</code></dt>
<dd>The ancillary data associated with the spectral library</dd>
<dt><code>ndarray</code></dt>
<dd>A numpy array of spectral data corresponding to the library</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_library(self):
    &#34;&#34;&#34;
    Return a pandas dataframe of entries in the spectral library and a numpy array of the spectra.
    Returns:
        Dataframe: The ancillary data associated with the spectral library
        ndarray: A numpy array of spectral data corresponding to the library

    &#34;&#34;&#34;
    return self.library_df, self.library_spectra</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.get_library_and_instrument_data"><code class="name flex">
<span>def <span class="ident">get_library_and_instrument_data</span></span>(<span>self, which_library)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>which_library ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_library_and_instrument_data(self, which_library):
    &#34;&#34;&#34;

    Args:
        which_library ():

    Returns:

    &#34;&#34;&#34;
    lib_df = None
    lib_spec = None
    range_index = self.range_indices

    inst_spec = self.spectral_input[:, range_index[0]:range_index[1]]
    if which_library == &#39;full&#39;:
        lib_df = self.instrument_library_df
        lib_spec = self.instrument_library_spectra[:, range_index[0]:range_index[1]]
    elif which_library == &#39;average&#39;:
        lib_df = self.average_instrument_library_df
        lib_spec = self.average_instrument_library_spectra[:, range_index[0]:range_index[1]]
    elif which_library == &#39;culled&#39;:
        lib_df = self.culled_df
        lib_spec = self.culled_spectra

    wavelengths = self.instrument_wavelengths[range_index[0]:range_index[1]]
    lib_spec[lib_spec &lt; 0] = 0
    inst_spec[inst_spec &lt; 0] = 0
    return lib_df, lib_spec, inst_spec, wavelengths</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.get_nmf_results"><code class="name flex">
<span>def <span class="ident">get_nmf_results</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nmf_results(self):
    &#34;&#34;&#34;

    Returns:

    &#34;&#34;&#34;
    return self.nmf_results, self.which_nmf</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.keep_library_above"><code class="name flex">
<span>def <span class="ident">keep_library_above</span></span>(<span>self, threshold=0.0)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>threshold ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def keep_library_above(self, threshold=0.0):
    &#34;&#34;&#34;

    Args:
        threshold ():

    Returns:

    &#34;&#34;&#34;
    # cut the last NMF result at some % proportion as either gt or lt
    if self.nmf_results is None:
        self.which_nmf = &#39;full&#39;
        # print(&#39;You need to fit some data first&#39;)
        # return ()

    # see what the last nmf results were generated from
    which_nmf = self.which_nmf
    temp_df, temp_spectra, _, wavelengths = self.get_library_and_instrument_data(which_nmf)

    # do a hull correction if asked for
    if self.hull or self.tir:
        lib_spec, _, _ = self._hull_corrections(wavelengths, temp_spectra, temp_spectra, self.tir)

    indices = np.where(np.max(lib_spec, axis=1) &gt; threshold)[0]

    return self.keep_specific(keep_these=indices, indices_supplied=True)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.keep_specific"><code class="name flex">
<span>def <span class="ident">keep_specific</span></span>(<span>self, keep_these=None, indices_supplied=False, keep_type='mineral')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>keep_these ():
indices_supplied ():
keep_type ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def keep_specific(self, keep_these=None, indices_supplied=False, keep_type=&#39;mineral&#39;):
    &#34;&#34;&#34;

    Args:
        keep_these ():
        indices_supplied ():
        keep_type ():

    Returns:

    &#34;&#34;&#34;
    # cut the last NMF result at some % proportion as either gt or lt
    if self.nmf_results is None:
        self.which_nmf = &#39;full&#39;
        # print(&#39;You need to fit some data first&#39;)
        # return ()

    # see what the last nmf results were generated from
    which_nmf = self.which_nmf
    temp_df, temp_spectra, _, _ = self.get_library_and_instrument_data(which_nmf)

    self.which_culled = which_nmf
    self.cull_type = &#39;grouped_&#39; + keep_type
    # first find out where the stuff is in the df so we can flag which spectra to drop as well
    if not indices_supplied:
        indices = temp_df[temp_df[keep_type].str.contains(&#39;|&#39;.join(keep_these))].index.values
    else:
        indices = keep_these

    if len(indices) &gt; 0:
        temp_df = temp_df.iloc[indices, :].reset_index(drop=True)
        temp_spectra = temp_spectra[indices, :]
        self.culled_df = temp_df
        self.culled_spectra = temp_spectra
        return self.fit(fit_to=&#39;culled&#39;)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.make_average_instrument_library"><code class="name flex">
<span>def <span class="ident">make_average_instrument_library</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This assumes that the spectral libraries contain mineral spectra. It groupsby the mineral names and produces an
average spectrum for each mineral.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>Sets the <code>internal average_instrument_library_spectra</code> and <code>average_instrument_library_df</code> variables</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_average_instrument_library(self):
    &#34;&#34;&#34;
    This assumes that the spectral libraries contain mineral spectra. It groupsby the mineral names and produces an
        average spectrum for each mineral.

    Returns:
        Nothing: Sets the `internal average_instrument_library_spectra` and `average_instrument_library_df` variables

    &#34;&#34;&#34;
    grouped_dict = self.instrument_library_df.groupby(&#39;mineral&#39;).indices
    mean_spectra = []
    temp_df = pd.DataFrame()
    for val in grouped_dict:
        indices = grouped_dict[val]
        mean_spectra.append(np.mean(self.instrument_library_spectra[indices, :], axis=0))
        temp_df = temp_df.append(self.instrument_library_df.iloc[indices[0], :])
    temp_df = temp_df.reset_index(drop=True)

    self.average_instrument_library_spectra = np.asarray(mean_spectra)
    self.average_instrument_library_df = temp_df</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.mixtures"><code class="name flex">
<span>def <span class="ident">mixtures</span></span>(<span>self, which_library='full', tir=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>which_library ():
tir ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mixtures(self, which_library=&#39;full&#39;, tir=False):
    &#34;&#34;&#34;
    
    Args:
        which_library ():
        tir ():

    Returns:

    &#34;&#34;&#34;
    # singleton
    lib_df, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(which_library)
    lib_spec, inst_spec, inst_hull = self._hull_corrections(wavelengths, inst_spec, lib_spec, tir=tir)

    # get all of the possible combinations of the end members up to a max mixture level e.g 1 through to 4
    lib_elements = list(np.arange(lib_spec.shape[0]))
    mixtures = []
    max_mixture_level = 4 # hard coded for trial
    for val in range(1, max_mixture_level+1):
        mixtures.append(list(combinations(lib_elements, val)))

    # run the NMF to calculate the weights for the potential mixture levels
    rms_error = []
    for val in mixtures[0]:
        nmf_results = non_negative_factorization(inst_spec, H=np.reshape(lib_spec[val[1], :], [1, -1]),
                                                 update_H=False, init=None,
                                                 n_components=2, max_iter=600, solver=&#39;mu&#39;,
                                                 beta_loss=1, tol=1.e-4, random_state=42)[:2]
        rms_error.append(np.sqrt(np.sum(np.square(np.dot(nmf_results[0][0], nmf_results[0][1]) - inst_spec), axis=1)))</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_grouped_proportions"><code class="name flex">
<span>def <span class="ident">plot_grouped_proportions</span></span>(<span>self, group=None, stacked=True, ax=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>group ():
stacked ():
ax ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_grouped_proportions(self, group=None, stacked=True, ax=None):
    &#34;&#34;&#34;

    Args:
        group ():
        stacked ():
        ax ():

    Returns:

    &#34;&#34;&#34;
    if group is None:
        group = [&#39;mineral&#39;]
    ax = ax or plt.gca()
    # plot the proportions of the last NMF run
    # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
    # your call

    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    cum_sum, names, props = self._group_and_sort_by_proportion(group)

    temp = []
    for index, name in enumerate(names):
        temp.append(name + &#39;|&#39; + str(np.round(props[index], 2)) + &#39;|&#39; + str(np.round(cum_sum[index], 2)))

    names = list(np.asarray(temp))

    # make a temporary data frame
    temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
    # todo allow people to change the color map
    colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))

    if len(group) &gt; 1:
        stacked = True
    if stacked:
        temp_df.plot.bar(stacked=True, legend=False, color=colors)
        # todo work out how many cols are needed based on len(names) and adjust accordingly
        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
        plt.subplots_adjust(right=0.4)
    else:
        plt.bar(names, props, color=colors)
        plt.xticks(rotation=90)
        plt.tight_layout()

    plt.show()</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_library_spectra"><code class="name flex">
<span>def <span class="ident">plot_library_spectra</span></span>(<span>self, search_item='mineral', names=None, plot_hull=False, tir=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>search_item ():
names ():
plot_hull ():
tir ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_library_spectra(self, search_item=&#39;mineral&#39;, names=None, plot_hull=False, tir=False):
    &#34;&#34;&#34;

    Args:
        search_item ():
        names ():
        plot_hull ():
        tir ():

    Returns:

    &#34;&#34;&#34;
    if names is None:
        return 0
    df = self.instrument_library_df
    wavelengths = self.instrument_wavelengths[self.range_indices[0]:self.range_indices[1]]
    spectra = self.instrument_library_spectra[:, self.range_indices[0]:self.range_indices[1]]
    if plot_hull:
        if tir:
            spectra = get_absorption(wavelengths, 1.0 - spectra, 1)
        else:
            spectra = get_absorption(wavelengths, spectra, 1)

    indices = df.loc[df[search_item].isin(names)].index.values
    if len(indices) &gt; 0:
        for val in indices:
            plt.plot(wavelengths, spectra[val, :], label=df[search_item].iloc[val])
        plt.legend()
        plt.show()</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_proportions"><code class="name flex">
<span>def <span class="ident">plot_proportions</span></span>(<span>self, plot_what='mineral', stacked=True)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>plot_what ():
stacked ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_proportions(self, plot_what=&#39;mineral&#39;, stacked=True):
    &#34;&#34;&#34;

    Args:
        plot_what ():
        stacked ():

    Returns:

    &#34;&#34;&#34;
    # plot the proportions of the last NMF run
    # todo return the axes and the figure so people can put it where they want
    # what_thing really can be anything from the data frame. Will it make sense though? Maybe not but that is
    # your call

    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    proportions = 100. * np.sum(self.nmf_results[0], axis=0) / np.sum(self.nmf_results[0])
    orders = np.argsort(proportions)
    props = proportions[orders]
    names = None

    which_nmf = self.which_nmf
    if which_nmf.lower() == &#39;full&#39;:
        names = self.instrument_library_df[plot_what].iloc[orders]
    elif which_nmf.lower() == &#39;average&#39;:
        names = self.average_instrument_library_df[plot_what].iloc[orders]
    elif which_nmf == &#39;culled&#39;:
        names = self.culled_df[plot_what].iloc[orders]

    # make a temporary data frame
    temp_df = pd.DataFrame(np.expand_dims(props, axis=0), columns=names)
    # todo allow people to change the color map
    colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
    if stacked:
        temp_df.plot.bar(stacked=True, legend=False, color=colors)
        # todo work out how many cols are needed based on len(names) and adjust accordingly
        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ncol=4)
        plt.subplots_adjust(right=0.55)
    else:
        plt.bar(np.arange(props.shape[0]), props, tick_label=names, color=colors)
        plt.xticks(rotation=90)
        plt.tight_layout()
    plt.show()</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_spectral_fit"><code class="name flex">
<span>def <span class="ident">plot_spectral_fit</span></span>(<span>self, index, plot_type='ref', what='mineral', top=3, total_contribution=False, ax=None, fill_between=True)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>index ():
plot_type ():
what ():
top ():
total_contribution ():
ax ():
fill_between ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_spectral_fit(self, index, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                      fill_between=True):
    &#34;&#34;&#34;

    Args:
        index ():
        plot_type ():
        what ():
        top ():
        total_contribution ():
        ax ():
        fill_between ():

    Returns:

    &#34;&#34;&#34;
    ax = ax or plt.gca()
    # get the fit
    nmf = self.nmf_results
    df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

    args = np.argsort(nmf[0][index, :])[-top:]
    top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
    contributions = np.round(np.flip(nmf[0][index, args]), 2)

    # get total contribution
    if total_contribution:
        grp = df.groupby(what).indices
        name = []
        amount = []
        for val in grp:
            name.append(val)
            amount.append(np.sum(nmf[0][index, grp[val]]))

        args = np.argsort(amount)[-top:]
        contributions = np.round(np.asarray(amount)[args], 2)
        top_minerals = np.asarray(name)[args]

    # get the nmf interpretation of the spectrum and the actual spectrum
    synthetic_spectrum = np.dot(nmf[0][index, :], nmf[1])
    actual_spectrum = instrument_spectra[index, :]

    # 1: TIR = True : Only need a baseline correction to the actual spectra
    # 2: Hull = True : Only need to get the actual spectra hull removed
    hull = None
    sf = None
    temp_spectrum = None
    if self.tir:
        actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
        sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
    if self.hull:
        hull = get_absorption(wavelengths, actual_spectrum, 2)
        temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
        sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

    if sf is None:
        scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
    else:
        scale_factor = sf

    # now its only about the display
    # can either be reflectance or hull
    # tir can only be reflectance
    if self.tir:
        synthetic_spectrum = synthetic_spectrum * scale_factor
    else:
        if plot_type == &#39;ref&#39;:
            synthetic_spectrum = hull - synthetic_spectrum * scale_factor
        else:
            synthetic_spectrum = synthetic_spectrum * scale_factor
            actual_spectrum = temp_spectrum

    minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
    seperator = &#39; + &#39;
    label = seperator.join(minerals)

    if fill_between:
        line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
        line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.5)
        line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.5)
    else:
        line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
        line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
    ax.set_xlabel(&#39;Wavelength (nm)&#39;)
    ax.set_ylabel(&#39;Reflectance&#39;)
    ax.legend()
    return wavelengths, actual_spectrum, synthetic_spectrum</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_spectral_fit_at_ordinate"><code class="name flex">
<span>def <span class="ident">plot_spectral_fit_at_ordinate</span></span>(<span>self, value, ordinates, plot_type='ref', what='mineral', top=3, total_contribution=False, ax=None, fill_between=True, mask=0, title=None, color=None, additional_label='', legend=True, return_contributions=False)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>value ():
ordinates ():
plot_type ():
what ():
top ():
total_contribution ():
ax ():
fill_between ():
mask ():
title ():
color ():
additional_label ():
legend ():
return_contributions ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_spectral_fit_at_ordinate(self, value, ordinates, plot_type=&#39;ref&#39;, what=&#39;mineral&#39;, top=3, total_contribution=False, ax=None,
                      fill_between=True, mask=0, title=None, color=None, additional_label=&#39;&#39;, legend=True, return_contributions=False):
    &#34;&#34;&#34;

    Args:
        value ():
        ordinates ():
        plot_type ():
        what ():
        top ():
        total_contribution ():
        ax ():
        fill_between ():
        mask ():
        title ():
        color ():
        additional_label ():
        legend ():
        return_contributions ():

    Returns:

    &#34;&#34;&#34;
    ax = ax or plt.gca()
    # get the fit
    nmf = self.nmf_results
    df, _, instrument_spectra, wavelengths = self.get_library_and_instrument_data(self.which_nmf)

    if not np.isscalar(mask):
        index = np.square(ordinates - ordinates[mask][np.square(ordinates[mask] - value).argmin()]).argmin()
        rms = self.rms_fit_error[mask][index]
        r2 = self.r2_fit_error[mask][index]
    else:
        index = np.square(ordinates - value).argmin()
        rms = self.rms_fit_error[index]
        r2 = self.r2_fit_error[index]

    args = np.argsort(nmf[0][index, :])[-top:]
    top_minerals = np.flip(df[&#39;mineral&#39;].loc[args].values)
    contributions = np.round(np.flip(nmf[0][index, args]), 2)

    # get total contribution
    if total_contribution:
        grp = df.groupby(what).indices
        name = []
        amount = []
        for val in grp:
            name.append(val)
            amount.append(np.sum(nmf[0][index, grp[val]]))

        args = np.argsort(amount)[-top:]
        contributions = np.round(np.asarray(amount)[args], 2)
        top_minerals = np.asarray(name)[args]
    return_minerals = (top_minerals, contributions)

    # get the nmf interpretation of the spectrum and the actual spectrum
    synthetic_spectrum = nmf[0][index, :].dot(nmf[1])
    actual_spectrum = instrument_spectra[index, :]

    # 1: TIR = True : Only need a baseline correction to the actual spectra
    # 2: Hull = True : Only need to get the actual spectra hull removed
    hull = None
    sf = None
    temp_spectrum = None
    if self.tir:
        actual_spectrum = get_absorption(wavelengths, 1.0 - actual_spectrum, 1)
        sf = np.max(actual_spectrum) / np.max(synthetic_spectrum)
    if self.hull:
        hull = get_absorption(wavelengths, actual_spectrum, 2)
        temp_spectrum = get_absorption(wavelengths, actual_spectrum, 1)
        sf = np.max(temp_spectrum) / np.max(synthetic_spectrum)

    if sf is None:
        scale_factor = np.max(actual_spectrum) / np.max(synthetic_spectrum)
    else:
        scale_factor = sf

    # now its only about the display
    # can either be reflectance or hull
    # tir can only be reflectance
    if self.tir:
        synthetic_spectrum = synthetic_spectrum * scale_factor
    else:
        if plot_type == &#39;ref&#39;:
            synthetic_spectrum = hull - synthetic_spectrum * scale_factor
        else:
            synthetic_spectrum = synthetic_spectrum * scale_factor
            actual_spectrum = temp_spectrum

    if top != 0:
        minerals = [val + &#39;(&#39; + str(contributions[index]) + &#39;)&#39; for index, val in enumerate(top_minerals)]
        seperator = &#39;, &#39;
        label = seperator.join(minerals) + &#39;, RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label
    else:
        label = &#39;RMS:&#39; + str(np.round(rms, 3)) + &#39;, R2:&#39; + str(np.round(r2, 3)) + &#39;:&#39; + additional_label

    # actual_spectrum += offset
    # synthetic_spectrum += offset
    if fill_between:
        line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
        if color:
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
        else:
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
        line3 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                where=synthetic_spectrum &gt; actual_spectrum, facecolor=&#39;blue&#39;, alpha=0.3)
        line4 = ax.fill_between(wavelengths, actual_spectrum, synthetic_spectrum,
                                where=synthetic_spectrum &lt; actual_spectrum, facecolor=&#39;green&#39;, alpha=0.3)
    else:
        line = ax.plot(wavelengths, actual_spectrum, color=&#39;k&#39;)
        if color:
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=color, label=label)
        else:
            line2 = ax.plot(wavelengths, synthetic_spectrum, color=&#39;firebrick&#39;, label=label)
    ax.set_xlabel(&#39;Wavelength (nm)&#39;, fontsize=16)
    ax.set_ylabel(&#39;Reflectance&#39;, fontsize=16)
    if title:
        ax.set_title(title, fontsize=20)
    if legend:
        ax.legend()
    return wavelengths, actual_spectrum, synthetic_spectrum, return_minerals</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_stacked_weight"><code class="name flex">
<span>def <span class="ident">plot_stacked_weight</span></span>(<span>self, x_ordinate, what_thing='mineral', partitions=1, ax=None, legend_ax=None, do_plotly=True, save_name='stacked_samples', hide_value=0, use_tsg_colors=False, mask=0, title='Relative Mineral Proportions', xtitle='Depth (m)')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>x_ordinate ():
what_thing ():
partitions ():
ax ():
legend_ax ():
do_plotly ():
save_name ():
hide_value ():
use_tsg_colors ():
mask ():
title ():
xtitle ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_stacked_weight(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=1, ax=None, legend_ax=None,
                        do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                        mask=0, title=&#34;Relative Mineral Proportions&#34;, xtitle=&#39;Depth (m)&#39;):
    &#34;&#34;&#34;

    Args:
        x_ordinate ():
        what_thing ():
        partitions ():
        ax ():
        legend_ax ():
        do_plotly ():
        save_name ():
        hide_value ():
        use_tsg_colors ():
        mask ():
        title ():
        xtitle ():

    Returns:

    &#34;&#34;&#34;
    if do_plotly is False:
        ax = ax or plt.gca()
        legend_ax = legend_ax or plt.gca()

    # plot the stacked weights from the last NMF run
    # which_nmf determines where the last result came from
    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
    args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
    temp_weights = self.nmf_results[0].copy()
    temp_weights = temp_weights[:, args]
    names = np.unique(temp_df[what_thing].iloc[args])
    temp_df = temp_df.iloc[args, :].reset_index(drop=True)

    # todo add in the nmf_results[1] into the mix so it can be passed back
    new_weight = []
    # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
    # mineral name todo change this a pandas groupby and indices call instead
    for name in names:
        args = np.where(temp_df[what_thing] == name)[0]
        new_weight.append(np.sum(temp_weights[:, args], axis=1))
    new_weight = np.transpose(np.asarray(new_weight))
    new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

    # find where the indices are that will let us split the data according to the user partition size
    split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
    if np.isscalar(mask):
        mask = np.ones(x_ordinate.shape).astype(bool)

    x_ordinate_split = np.split(x_ordinate, split_locations)
    new_weight_split = np.split(new_weight, split_locations)
    mask_split = np.split(mask, split_locations)

    depth = []
    width = []
    weight = []

    count = 0
    if np.min(np.diff(x_ordinate)) &lt; partitions:
        for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
            if xval.shape[0] &gt; 0:
                depth.append(xval[0])
                width.append(xval[-1]-xval[0])
                any_masked = float(np.where(mask_val)[0].shape[0])
                # if nothing is masked then dont average
                if any_masked &gt; 0:
                    weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                else:
                    weight.append(np.sum(weight_val[mask_val, :], axis=0))
    else:
        depth = x_ordinate
        width = np.zeros((depth.shape[0])) + partitions
        weight = new_weight[mask]

    weight = np.asarray(weight)
    depth = np.asarray(depth)
    width = np.asarray(width)

    tdepth = [str(int(val)) for val in depth]
    new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
    colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
    if not do_plotly:
        new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
    else:
        if hide_value &gt; 0:
            args = np.where(weight &lt; hide_value)
            weight[args[0], args[1]] = np.nan
            # normalize
            weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

        data = []
        for var in np.arange(weight.shape[1]):
            if what_thing == &#39;mineral&#39;:
                thing = &#39;Mineral&#39;
            elif what_thing == &#39;group&#39;:
                thing = &#39;Group&#39;
            else:
                use_tsg_colors = False

        color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours.csv&#34;)
        for val in np.unique(temp_df[&#39;group&#39;]):
            unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
            number_of_minerals = unique_minerals.shape[0]
            group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
            # lets get alpha values
            rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
            alphas = np.linspace(1.0, 0.5, number_of_minerals)
            # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
            # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
            # rgb = rgb.astype(int)
            for index, mineral in enumerate(unique_minerals):
                #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                location = np.where(names == mineral)[0][0]
                data.append(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                     marker_color=color))

        fig = go.Figure(data=data)
        # Change the bar mode
        # todo put in keywords for titles and labels
        title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
        fig.update_layout(barmode=&#39;stack&#39;, title=title, xaxis_title=xtitle,
                          yaxis_title=&#34;Relative Proportion&#34;, legend_orientation=&#34;h&#34;, font_size=20)
        fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
        fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
        fig.write_html(save_name+&#34;.html&#34;)

    return names, depth, np.nan_to_num(weight, 0)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.plot_stacked_weight_hack"><code class="name flex">
<span>def <span class="ident">plot_stacked_weight_hack</span></span>(<span>self, x_ordinate, what_thing='mineral', partitions=100, ax=None, legend_ax=None, do_plotly=True, save_name='stacked_samples', hide_value=0, use_tsg_colors=False, mask=0, title='Relative Mineral Proportions')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>x_ordinate ():
what_thing ():
partitions ():
ax ():
legend_ax ():
do_plotly ():
save_name ():
hide_value ():
use_tsg_colors ():
mask ():
title ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_stacked_weight_hack(self, x_ordinate, what_thing=&#39;mineral&#39;, partitions=100, ax=None, legend_ax=None,
                        do_plotly=True, save_name=&#39;stacked_samples&#39;, hide_value=0, use_tsg_colors=False,
                        mask=0, title=&#34;Relative Mineral Proportions&#34;):
    &#34;&#34;&#34;

    Args:
        x_ordinate ():
        what_thing ():
        partitions ():
        ax ():
        legend_ax ():
        do_plotly ():
        save_name ():
        hide_value ():
        use_tsg_colors ():
        mask ():
        title ():

    Returns:

    &#34;&#34;&#34;

    if do_plotly is False:
        ax = ax or plt.gca()
        legend_ax = legend_ax or plt.gca()

    if self.nmf_results is None:
        print(&#39;You need to fit some data first&#39;)
        return ()

    temp_df, _, _, _ = self.get_library_and_instrument_data(self.which_nmf)
    args = np.where(np.sum(self.nmf_results[0], axis=0) / self.nmf_results[0].shape[0] &gt; hide_value)[0]
    temp_weights = self.nmf_results[0].copy()[:, args]
    names = np.unique(temp_df[what_thing].iloc[args])
    temp_df = temp_df.iloc[args, :].reset_index(drop=True)

    new_weight = []
    # sum the results as a function of &#39;what_thing&#39;. If its &#39;mineral&#39; then this is effectively grouping by
    # mineral name todo change this a pandas groupby and indices call instead
    for name in names:
        args = np.where(temp_df[what_thing] == name)[0]
        new_weight.append(np.sum(temp_weights[:, args], axis=1))
    new_weight = np.transpose(np.asarray(new_weight))
    new_weight /= np.expand_dims(np.nansum(new_weight, axis=1), axis=1)

    # find where the indices are that will let us split the data according to the user partition size
    split_locations = np.searchsorted(x_ordinate, np.arange(partitions, x_ordinate[-1], partitions))
    if np.isscalar(mask):
        mask = np.ones(x_ordinate.shape).astype(bool)

    x_ordinate_split = np.split(x_ordinate, split_locations)
    new_weight_split = np.split(new_weight, split_locations)
    mask_split = np.split(mask, split_locations)

    depth = []
    width = []
    weight = []

    count=0
    if np.min(np.diff(x_ordinate)) &lt; partitions:
        for xval, weight_val, mask_val in zip(x_ordinate_split, new_weight_split, mask_split):
            if xval.shape[0] &gt; 0:
                depth.append(xval[0])
                width.append(xval[-1]-xval[0])
                any_masked = float(np.where(mask_val)[0].shape[0])
                # if nothing is masked then dont average
                if any_masked &gt; 0:
                    weight.append(np.sum(weight_val[mask_val, :], axis=0)/any_masked)
                else:
                    weight.append(np.sum(weight_val[mask_val, :], axis=0))
    else:
        depth = x_ordinate
        width = np.zeros((depth.shape[0])) + partitions
        weight = new_weight[mask]

    weight = np.asarray(weight)
    depth = np.asarray(depth)
    width = np.asarray(width)

    tdepth = [str(int(val)) for val in depth]
    new_dataframe = pd.DataFrame(weight, columns=names, index=tdepth)
    colors = plt.cm.tab20b(np.linspace(0, 1, len(names)))
    if not do_plotly:
        new_dataframe.plot(ax=ax, kind=&#39;bar&#39;, stacked=True, width=np.asarray(width), legend=False, color=colors)
    else:
        if hide_value &gt; 0:
            args = np.where(weight &lt; hide_value)
            weight[args[0], args[1]] = np.nan
            # normalize
            weight /= np.expand_dims(np.nansum(weight, axis=1), axis=1)

        from plotly.subplots import make_subplots
        fig = make_subplots(rows=3, cols=1, #shared_xaxes=True,
                            specs=[[{}], [{&#34;rowspan&#34;:2}], [None]])

        # todo add in a bit for group plots not just mineral
        data = []
        color_data = pd.read_csv(&#34;spex/data/spectral_libraries/working_up_colours_mkII.csv&#34;)
        for val in np.unique(temp_df[&#39;group&#39;]):
            unique_minerals = np.unique(temp_df[temp_df[&#39;group&#39;] == val][what_thing])
            number_of_minerals = unique_minerals.shape[0]
            group_color_name = color_data[color_data[&#39;Group&#39;] == val][&#39;name&#39;].iloc[0]
            # lets get alpha values
            rgb = color_data[color_data[&#39;Group&#39;] == val][[&#39;Red&#39;, &#39;Blue&#39;, &#39;Green&#39;]].iloc[0]
            alphas = np.linspace(1.0, 0.5, number_of_minerals)
            # colors = sb.dark_palette(group_color_name, n_colors=3 + number_of_minerals)
            # rgb = np.asarray(colors[-number_of_minerals:]) * int(255)
            # rgb = rgb.astype(int)
            for index, mineral in enumerate(unique_minerals):
                #color = &#34;rgb(&#34; + str(rgb[index, 0]) + &#34;,&#34; + str(rgb[index, 1]) + &#34;,&#34; + str(rgb[index, 2]) + &#34;)&#34;
                color = &#34;rgba(&#34; + str(rgb[&#39;Red&#39;]) + &#34;,&#34; + str(rgb[&#39;Green&#39;]) + &#34;,&#34; + str(rgb[&#39;Blue&#39;]) + &#34;,&#34; + str(alphas[index]) + &#34;)&#34;
                location = np.where(names == mineral)[0][0]
                fig.add_trace(go.Bar(name=mineral, x=depth + width / 2, y=weight[:, location], width=width,
                                     marker_color=color), row=2, col=1)

        # MSDP11 HACK
        msdp11_df = pd.read_csv(&#39;msdp11_log.csv&#39;)
        lithology = msdp11_df.columns.values[2:]
        x = msdp11_df[&#39;X&#39;].values.astype(int)
        w = msdp11_df[&#39;Width&#39;].values.astype(int)
        colors=[&#34;brown&#34;, &#34;saddlebrown&#34;, &#34;lightyellow&#34;, &#34;pink&#34;, &#34;red&#34;, &#34;skyblue&#34;, &#34;olivedrab&#34;, &#34;darkgray&#34;, &#34;gray&#34;, &#34;indianred&#34;, &#34;purple&#34;]

        for index, var in enumerate(lithology):
            y = msdp11_df[var].values
            fig.add_trace(go.Bar(name=var, x=x+w/2, y=y, width=w, marker_color=colors[index]), row=1, col=1)

        # Change the bar mode
        # todo put in keywords for titles and labels
        title = title + &#39; , Bin Size: &#39; + str(partitions) + &#39;: Minimum Spatial Threshold = &#39; + str(hide_value)
        fig.update_layout(barmode=&#39;stack&#39;, title=title, legend_orientation=&#34;h&#34;, font_size=20)
        fig.update_yaxes(showticklabels=False, row=1, col=1)
        fig.update_xaxes(title_text=&#39;Depth (m)&#39;, row=2, col=1)
        fig.update_yaxes(title_text=&#39;Relative Proportion&#39;, row=2, col=1)
        fig.write_image(save_name+&#34;.png&#34;, width=1920, height=1080, scale=2)
        fig.write_image(save_name+&#34;.pdf&#34;, width=1920, height=1080, scale=2)
        fig.write_html(save_name+&#34;.html&#34;)

    return names, depth, np.nan_to_num(weight, 0)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.r2_error"><code class="name flex">
<span>def <span class="ident">r2_error</span></span>(<span>self, fit_to='full')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>fit_to ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def r2_error(self, fit_to=&#39;full&#39;):
    &#34;&#34;&#34;

    Args:
        fit_to ():

    Returns:

    &#34;&#34;&#34;
    # set the user spectral input
    if self.spectral_input is None:
        print(&#39;You need to enter input data to run the analysis &#39;)
        return 0

    if fit_to == &#39;culled&#39;:
        if self.culled_df is None:
            print(&#39;You need to cull something first&#39;)
            return 0

    # get the library &amp; instrument data
    _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

    # do a hull correction if asked for
    if self.hull or self.tir:
        lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

    synth = np.dot(self.nmf_results[0], self.nmf_results[1])

    # normalise the spectra
    synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

    # store the result and return them
    from scipy.stats import pearsonr
    r2 = [pearsonr(val1, val2)[0] for val1, val2 in zip(inst_spec, synthetics)]

    return np.asarray(r2)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.rms_error"><code class="name flex">
<span>def <span class="ident">rms_error</span></span>(<span>self, fit_to='full')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>fit_to ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rms_error(self, fit_to=&#39;full&#39;):
    &#34;&#34;&#34;

    Args:
        fit_to ():

    Returns:

    &#34;&#34;&#34;
    # set the user spectral input
    if self.spectral_input is None:
        print(&#39;You need to enter input data to run the analysis &#39;)
        return 0

    if fit_to == &#39;culled&#39;:
        if self.culled_df is None:
            print(&#39;You need to cull something first&#39;)
            return 0

    # get the library &amp; instrument data
    _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

    # do a hull correction if asked for
    if self.hull or self.tir:
        lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

    synth = np.dot(self.nmf_results[0], self.nmf_results[1])

    # normalise the spectra
    synthetics, inst_spec = self._normalise_the_spectra(inst_spec, synth)

    # store the result and return them
    rms_error = np.sqrt(
        np.sum(np.square(inst_spec - synthetics), axis=1) / wavelengths.shape[0])
    return rms_error</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.set_external_library"><code class="name flex">
<span>def <span class="ident">set_external_library</span></span>(<span>self, wavelengths, spectra, names)</span>
</code></dt>
<dd>
<div class="desc"><p>Use external user supplied spectra as the spectral library</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>wavelengths</code></strong> :&ensp;<code>ndarry</code></dt>
<dd>An array of wavelengths (B) in nanometers corresponding to the number of entries in an
individual spectrum contained in spectra.</dd>
<dt><strong><code>spectra</code></strong> :&ensp;<code>ndarray</code></dt>
<dd>An array of spectra (NxB) representing a user defined spectral endmember</dd>
<dt><strong><code>names</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of names (N) for each spectrum in spectra</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>Sets internal variables</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_external_library(self, wavelengths, spectra, names):
    &#34;&#34;&#34;
    Use external user supplied spectra as the spectral library
    Args:
        wavelengths (ndarry): An array of wavelengths (B) in nanometers corresponding to the number of entries in an
            individual spectrum contained in spectra.
        spectra (ndarray): An array of spectra (NxB) representing a user defined spectral endmember
        names (list): A list of names (N) for each spectrum in spectra

    Returns:
        Nothing: Sets internal variables

    &#34;&#34;&#34;
    self.library_df = pd.DataFrame(names, columns=[&#39;mineral&#39;])
    self.library_spectra = spectra
    self.library_wavelengths = wavelengths

    self.convert_library_to_instrument()
    self.make_average_instrument_library()
    self.range_indices = find_indices(self.spectral_range, self.instrument_wavelengths)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.set_library"><code class="name flex">
<span>def <span class="ident">set_library</span></span>(<span>self, library=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Set which spectral library to use (from the 3 inbuilt available)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>library</code></strong> :&ensp;<code>str</code></dt>
<dd>The library to use ofr calculations</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Nothing</code></dt>
<dd>Sets internal variables</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_library(self, library=None):
    &#34;&#34;&#34;
    Set which spectral library to use (from the 3 inbuilt available)
    Args:
        library (str): The library to use ofr calculations

    Returns:
        Nothing: Sets internal variables
    &#34;&#34;&#34;
    if library is None:
        print(&#34;Nope. You didn&#39;t select a library&#34;)
    else:
        library_df = library + &#39;_df.csv&#39;
        library_spectra = library + &#39;_spectra.csv&#39;
        library_df_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_df)
        self.library_df = pd.read_csv(library_df_read, index_col=0)
        library_spectra_read = pkg_resources.resource_stream(__name__, &#39;spectral_libraries/&#39; + library_spectra)
        spectra_df = pd.read_csv(library_spectra_read, index_col=0)
        self.library_spectra = spectra_df.values
        self.library_wavelengths = 1000.0 * spectra_df.columns.values.astype(&#39;float&#39;)</code></pre>
</details>
</dd>
<dt id="spex.speclib.speclib.SpectralMix.tag_spectra_below_a_maximum_threshold"><code class="name flex">
<span>def <span class="ident">tag_spectra_below_a_maximum_threshold</span></span>(<span>self, threshold=0.01, fit_to='full')</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<p>threshold ():
fit_to ():
Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tag_spectra_below_a_maximum_threshold(self, threshold=0.01, fit_to=&#39;full&#39;):
    &#34;&#34;&#34;

    Args:
        threshold ():
        fit_to ():

    Returns:

    &#34;&#34;&#34;
    # set the user spectral input
    if self.spectral_input is None:
        print(&#39;You need to enter input data to run the analysis &#39;)
        return 0

    if fit_to == &#39;culled&#39;:
        if self.culled_df is None:
            print(&#39;You need to cull something first&#39;)
            return 0

    # get the library &amp; instrument data
    _, lib_spec, inst_spec, wavelengths = self.get_library_and_instrument_data(fit_to)

    # do a hull correction if asked for
    if self.hull or self.tir:
        lib_spec, inst_spec, _ = self._hull_corrections(wavelengths, inst_spec, lib_spec, self.tir)

    return np.max(inst_spec, axis=1) &lt; threshold</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="spex.speclib" href="index.html">spex.speclib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="spex.speclib.speclib.SpectralMix" href="#spex.speclib.speclib.SpectralMix">SpectralMix</a></code></h4>
<ul class="">
<li><code><a title="spex.speclib.speclib.SpectralMix.compare_instrument_spectra_to_specific" href="#spex.speclib.speclib.SpectralMix.compare_instrument_spectra_to_specific">compare_instrument_spectra_to_specific</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.convert_library_to_instrument" href="#spex.speclib.speclib.SpectralMix.convert_library_to_instrument">convert_library_to_instrument</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.cull_by_cumulative_proportion" href="#spex.speclib.speclib.SpectralMix.cull_by_cumulative_proportion">cull_by_cumulative_proportion</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.cull_by_grouped" href="#spex.speclib.speclib.SpectralMix.cull_by_grouped">cull_by_grouped</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.cull_by_individual_and_total_sample_contribution" href="#spex.speclib.speclib.SpectralMix.cull_by_individual_and_total_sample_contribution">cull_by_individual_and_total_sample_contribution</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.cull_by_rank" href="#spex.speclib.speclib.SpectralMix.cull_by_rank">cull_by_rank</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.cull_entries" href="#spex.speclib.speclib.SpectralMix.cull_entries">cull_entries</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.drop_specific" href="#spex.speclib.speclib.SpectralMix.drop_specific">drop_specific</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.fit" href="#spex.speclib.speclib.SpectralMix.fit">fit</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.get_average_instrument_library" href="#spex.speclib.speclib.SpectralMix.get_average_instrument_library">get_average_instrument_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.get_instrument_library" href="#spex.speclib.speclib.SpectralMix.get_instrument_library">get_instrument_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.get_library" href="#spex.speclib.speclib.SpectralMix.get_library">get_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.get_library_and_instrument_data" href="#spex.speclib.speclib.SpectralMix.get_library_and_instrument_data">get_library_and_instrument_data</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.get_nmf_results" href="#spex.speclib.speclib.SpectralMix.get_nmf_results">get_nmf_results</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.keep_library_above" href="#spex.speclib.speclib.SpectralMix.keep_library_above">keep_library_above</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.keep_specific" href="#spex.speclib.speclib.SpectralMix.keep_specific">keep_specific</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.make_average_instrument_library" href="#spex.speclib.speclib.SpectralMix.make_average_instrument_library">make_average_instrument_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.mixtures" href="#spex.speclib.speclib.SpectralMix.mixtures">mixtures</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_grouped_proportions" href="#spex.speclib.speclib.SpectralMix.plot_grouped_proportions">plot_grouped_proportions</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_library_spectra" href="#spex.speclib.speclib.SpectralMix.plot_library_spectra">plot_library_spectra</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_proportions" href="#spex.speclib.speclib.SpectralMix.plot_proportions">plot_proportions</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_spectral_fit" href="#spex.speclib.speclib.SpectralMix.plot_spectral_fit">plot_spectral_fit</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_spectral_fit_at_ordinate" href="#spex.speclib.speclib.SpectralMix.plot_spectral_fit_at_ordinate">plot_spectral_fit_at_ordinate</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_stacked_weight" href="#spex.speclib.speclib.SpectralMix.plot_stacked_weight">plot_stacked_weight</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.plot_stacked_weight_hack" href="#spex.speclib.speclib.SpectralMix.plot_stacked_weight_hack">plot_stacked_weight_hack</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.r2_error" href="#spex.speclib.speclib.SpectralMix.r2_error">r2_error</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.rms_error" href="#spex.speclib.speclib.SpectralMix.rms_error">rms_error</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.set_external_library" href="#spex.speclib.speclib.SpectralMix.set_external_library">set_external_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.set_library" href="#spex.speclib.speclib.SpectralMix.set_library">set_library</a></code></li>
<li><code><a title="spex.speclib.speclib.SpectralMix.tag_spectra_below_a_maximum_threshold" href="#spex.speclib.speclib.SpectralMix.tag_spectra_below_a_maximum_threshold">tag_spectra_below_a_maximum_threshold</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>